{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratyushJha254/BTP/blob/main/NNs_trainedOnFerro_testedOnAntiFerro_NNIsingModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the following:\n",
        "1.   Code NNs using pytorch, test over NNN Ising Model.\n",
        "2.   Train the model using antiferro data.\n",
        "3.   Train on ferro test on anti-ferro (first discuss with Sir).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tih5gFAocas0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CH9ENwKBYeOY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import pickle\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcol\n",
        "import matplotlib.cm as cm\n",
        "from keras.utils import to_categorical\n",
        "import keras.layers as layers\n",
        "from keras import Sequential\n",
        "from numba import jit\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad as torch_grad\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Metropolis Algorithm"
      ],
      "metadata": {
        "id": "DZUcbnKRp0LW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxP8qAFiZ5eZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import jit\n",
        "\n",
        "@jit(nopython=True)\n",
        "def data_generation_internal(l, J=1):\n",
        "    # J = 1  # coupling strength\n",
        "    L = l  # grid size\n",
        "\n",
        "    temperatures = np.arange(1, 3.51, 0.1)  # 26\n",
        "    ntherm = 100  # thermalization steps\n",
        "    nsamples = 100  # number of samples for every starting configuration\n",
        "    nbin = 10  # number of starting configurations\n",
        "\n",
        "    n = len(temperatures) * nbin * nsamples  # total number of samples\n",
        "\n",
        "    C = np.empty((n, L, L))\n",
        "    T = np.empty(n)\n",
        "\n",
        "    # checkerboard pattern\n",
        "    x = np.zeros((L, L), dtype=np.int64)\n",
        "    x[1::2, 0::2] = 1\n",
        "    x[0::2, 1::2] = 1\n",
        "\n",
        "    c = 0\n",
        "    for t in temperatures:\n",
        "        for i in range(nbin):\n",
        "            # start with polarized state\n",
        "            grid = np.ones((L, L)) * (-1)**(i % 2)\n",
        "            # draw a number of sample configurations\n",
        "            for j in range(nsamples):\n",
        "                # perform a number of updates until thermalization\n",
        "                for k in range(ntherm):\n",
        "                    # Calculate neighbors without using np.roll()\n",
        "                    neighbors = np.zeros((L, L))\n",
        "                    neighbors[:-1, :] += grid[1:, :]\n",
        "                    neighbors[1:, :] += grid[:-1, :]\n",
        "                    neighbors[:, :-1] += grid[:, 1:]\n",
        "                    neighbors[:, 1:] += grid[:, :-1]\n",
        "                    # calculate the potential changes in energy\n",
        "                    dE = 2 * J * (grid * neighbors)\n",
        "                    # calculate the transition probabilities\n",
        "                    p = np.exp(-dE / t)\n",
        "                    # decide which transitions will occur\n",
        "                    # (avoid updating neighbors using alternating checkerboard pattern)\n",
        "                    grid *= 1 - 2 * np.multiply((np.random.rand(L, L) < p).astype(np.int8), x ^ (k % 2))\n",
        "\n",
        "                C[c] = grid\n",
        "                T[c] = t\n",
        "                c += 1\n",
        "\n",
        "    return C, T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generation(l, name, J):\n",
        "    C, T = data_generation_internal(l, J)\n",
        "    p = np.random.permutation(len(C))\n",
        "    np.savez_compressed(name, X=C[p], y=T[p])"
      ],
      "metadata": {
        "id": "_695L5ZXJIuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhxKd4C0Z5ea"
      },
      "outputs": [],
      "source": [
        "# data_generation(10, 'data1.npz', 1)\n",
        "# data_generation(20, 'data2.npz', 1)\n",
        "# data_generation(30, 'data3.npz', 1)\n",
        "# data_generation(40, 'data4.npz', 1)\n",
        "data_generation(64, 'data_anti.npz', -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the file"
      ],
      "metadata": {
        "id": "bm-eCHQ5p5dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nu_G = 10\n",
        "Ny = 64\n",
        "Nx = 64\n",
        "nc = 1\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "num_epochs = 50\n",
        "lr = 0.001\n",
        "beta1 = 0.5\n",
        "ngpu = 1\n",
        "N = Ny * Nx\n",
        "device = torch.device('cuda:0' if (torch.cuda.is_available() and ngpu > 0) else 'cpu')"
      ],
      "metadata": {
        "id": "Z2YO9EViStuz"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wwq4a69qZ5eb"
      },
      "outputs": [],
      "source": [
        "def file_loader(file_name):\n",
        "    data = np.load(file_name)\n",
        "    X = data['X']\n",
        "    y = data['y']\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.15)\n",
        "    Tc = 2.27 # For a square lattice following Ising Model\n",
        "    y_train = Y_train > Tc\n",
        "    y_test = Y_test > Tc\n",
        "    y_train = to_categorical(y_train.astype(int))\n",
        "    y_test = to_categorical(y_test.astype(int))\n",
        "    return X_train, X_test, y_train, y_test, Y_train, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y_8X1AJRZAaN"
      },
      "outputs": [],
      "source": [
        "# data -\n",
        "\n",
        "# X_train1, X_test1, y_train1, y_test1, Y_train1, Y_test1 = file_loader('data1.npz')\n",
        "\n",
        "# X_train2, X_test2, y_train2, y_test2, Y_train2, Y_test2 = file_loader('data2.npz')\n",
        "\n",
        "# X_train3, X_test3, y_train3, y_test3, Y_train3, Y_test3 = file_loader('data3.npz')\n",
        "\n",
        "# X_train4, X_test4, y_train4, y_test4, Y_train4, Y_test4 = file_loader('data4.npz')\n",
        "\n",
        "X_train, X_test, y_train, y_test, Y_train, Y_test = file_loader('data.npz')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_anti, X_test_anti, y_train_anti, y_test_anti, Y_train_anti, Y_test_anti = file_loader('data_anti.npz')"
      ],
      "metadata": {
        "id": "puu1oIW8oxg1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset and DataLoader"
      ],
      "metadata": {
        "id": "BSS1i0APqJnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IsingDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.n_samples = x.shape[0]\n",
        "        self.x = torch.tensor(torch.from_numpy(x))\n",
        "        self.y = torch.tensor(torch.from_numpy(y))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "OvGVpjWwJi8J"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = IsingDataset(X_train, y_train)\n",
        "testing_dataset = IsingDataset(X_test, y_test)\n",
        "batch_size = 128\n",
        "train_dataloader = DataLoader(dataset = training_dataset, batch_size = batch_size, shuffle = False)\n",
        "test_dataloader = DataLoader(dataset = testing_dataset, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxE4frNKJw4y",
        "outputId": "a0d0dd21-df01-406f-ddae-822ccae9635b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-de2182b412d1>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.x = torch.tensor(torch.from_numpy(x))\n",
            "<ipython-input-70-de2182b412d1>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(torch.from_numpy(y))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset_anti = IsingDataset(X_train_anti, y_train_anti)\n",
        "testing_dataset_anti = IsingDataset(X_test_anti, y_test_anti)\n",
        "batch_size = 128\n",
        "train_dataloader_anti = DataLoader(dataset = training_dataset_anti, batch_size = batch_size, shuffle = False)\n",
        "test_dataloader_anti = DataLoader(dataset = testing_dataset_anti, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWZOcCBUobIc",
        "outputId": "cadf59ca-f603-40ec-b76e-724ce92d73c0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-de2182b412d1>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.x = torch.tensor(torch.from_numpy(x))\n",
            "<ipython-input-70-de2182b412d1>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(torch.from_numpy(y))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accuracy, train and test functions"
      ],
      "metadata": {
        "id": "RZDqQL9sqtt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(outputs, labels):\n",
        "    # Threshold the outputs at 0.5 to get binary predictions: below 0.5 becomes 0, above becomes 1\n",
        "    predicted = (outputs > 0.5).float()\n",
        "\n",
        "    # The labels need to have the same dimensions as the predictions for comparison\n",
        "    # Assuming labels are already in the correct shape (batch_size, 1) or (batch_size,)\n",
        "    # If not, you might need to adjust labels' shape, e.g., labels = labels.view(-1, 1)\n",
        "\n",
        "    # Calculate the number of correct predictions\n",
        "    correct = (predicted == labels).float().sum().item()/2\n",
        "\n",
        "    # Calculate the total number of labels (which is also the batch size)\n",
        "    total = labels.size(0)\n",
        "\n",
        "    # Calculate accuracy as the percentage of correct predictions\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "hOTDhh6OcgX9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, num_epochs, criterion, optimizer, train_dataloader):\n",
        "  for epoch in range(num_epochs):\n",
        "    for i, (x, label) in enumerate(train_dataloader):\n",
        "      x = x.to(device).float()\n",
        "      label = label.to(device).float()\n",
        "      b_size = x.size(0)\n",
        "      model.zero_grad()\n",
        "      output = model(x)\n",
        "      if(epoch==0 and i==0):\n",
        "        print(output)\n",
        "      error = criterion(output, label)\n",
        "      error.backward()\n",
        "      optimizer.step()\n",
        "      acc_train = calculate_accuracy(output, label)\n",
        "      if i % 20 == 0:\n",
        "        print('Loss:', error.item(),',Train accuracy:', acc_train)"
      ],
      "metadata": {
        "id": "nOqtvmF4R72B"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, criterion, test_dataloader):\n",
        "    for i, (x, label) in enumerate(test_dataloader):\n",
        "      x = x.to(device).float()\n",
        "      label = label.to(device).float()\n",
        "      output = model(x)\n",
        "      error = criterion(output, label)\n",
        "      acc_train = calculate_accuracy(output, label)\n",
        "      if i % 20 == 0:\n",
        "        print('Loss:', error.item(),',Test accuracy:', acc_train)"
      ],
      "metadata": {
        "id": "lkWQ7iweqBZ9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(test_loader, model):\n",
        "    # Assuming `test_loader` is your DataLoader for the test dataset\n",
        "    # Iterate over the test data and make predictions\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():  # Disable gradient tracking during inference\n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(device)  # Move inputs to the device (e.g., GPU)\n",
        "            _, predicted = torch.max(outputs, 1)  # Get the predicted class indices\n",
        "            all_predictions.extend(outputs.cpu().numpy())  # Convert predictions to CPU and store them\n",
        "\n",
        "    # Now `all_predictions` contains the predicted class indices for all test samples\n",
        "    # You can further process or save these predictions as needed\n"
      ],
      "metadata": {
        "id": "RZQwaexTynZw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jru3T1Rz1aRh"
      },
      "source": [
        "#### Fully Connected Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class neural_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(neural_network, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Flatten(start_dim=1,end_dim=-1),\n",
        "        nn.Linear(Nx*Ny, 100),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(100, 2),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, input):\n",
        "      return self.main(input)"
      ],
      "metadata": {
        "id": "0lSfsrZCJ-0V"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PziWo7Y6U9GY",
        "outputId": "a2df0a79-03cf-4a46-c9ab-dde08c929c03"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FCNN = neural_network().to(device)\n",
        "criterion_FCNN = nn.BCELoss()\n",
        "optimizer_FCNN = optim.Adam(FCNN.parameters(), lr=lr, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "K-euoH6nSSQP"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "train(FCNN, num_epochs, criterion_FCNN, optimizer_FCNN, train_dataloader)"
      ],
      "metadata": {
        "id": "yam54zMZeAXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179c68d0-ca31-43d3-c31b-fe8259aceb02"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3712, 0.4709],\n",
            "        [0.3539, 0.4499],\n",
            "        [0.3542, 0.4511],\n",
            "        [0.3708, 0.4715],\n",
            "        [0.3688, 0.4860],\n",
            "        [0.3831, 0.4698],\n",
            "        [0.3410, 0.4622],\n",
            "        [0.3744, 0.4673],\n",
            "        [0.3580, 0.4440],\n",
            "        [0.3502, 0.5152],\n",
            "        [0.3472, 0.4766],\n",
            "        [0.3710, 0.4709],\n",
            "        [0.3654, 0.4616],\n",
            "        [0.3701, 0.4811],\n",
            "        [0.3486, 0.4710],\n",
            "        [0.3403, 0.4381],\n",
            "        [0.3976, 0.4630],\n",
            "        [0.3729, 0.4687],\n",
            "        [0.3935, 0.4552],\n",
            "        [0.3730, 0.4715],\n",
            "        [0.3660, 0.4674],\n",
            "        [0.3639, 0.4560],\n",
            "        [0.3344, 0.4789],\n",
            "        [0.3725, 0.4534],\n",
            "        [0.3547, 0.4532],\n",
            "        [0.3544, 0.4470],\n",
            "        [0.3577, 0.4630],\n",
            "        [0.3529, 0.4501],\n",
            "        [0.3673, 0.4612],\n",
            "        [0.3722, 0.4720],\n",
            "        [0.3727, 0.4701],\n",
            "        [0.3297, 0.4403],\n",
            "        [0.3658, 0.4639],\n",
            "        [0.3700, 0.4679],\n",
            "        [0.3701, 0.4690],\n",
            "        [0.3564, 0.4558],\n",
            "        [0.3837, 0.4497],\n",
            "        [0.3734, 0.4718],\n",
            "        [0.3434, 0.4698],\n",
            "        [0.3931, 0.4348],\n",
            "        [0.3632, 0.4451],\n",
            "        [0.3568, 0.4595],\n",
            "        [0.3520, 0.4499],\n",
            "        [0.3616, 0.4529],\n",
            "        [0.3538, 0.4470],\n",
            "        [0.3547, 0.4501],\n",
            "        [0.3660, 0.4300],\n",
            "        [0.3500, 0.4623],\n",
            "        [0.3886, 0.4359],\n",
            "        [0.3613, 0.4462],\n",
            "        [0.3468, 0.4574],\n",
            "        [0.3492, 0.4656],\n",
            "        [0.3733, 0.4665],\n",
            "        [0.3542, 0.4510],\n",
            "        [0.3715, 0.4770],\n",
            "        [0.3547, 0.4493],\n",
            "        [0.3379, 0.4375],\n",
            "        [0.3232, 0.4742],\n",
            "        [0.3540, 0.4537],\n",
            "        [0.3361, 0.4323],\n",
            "        [0.3493, 0.4835],\n",
            "        [0.3619, 0.4694],\n",
            "        [0.3570, 0.4357],\n",
            "        [0.3569, 0.4486],\n",
            "        [0.3595, 0.4428],\n",
            "        [0.3552, 0.4469],\n",
            "        [0.3748, 0.4840],\n",
            "        [0.3573, 0.4962],\n",
            "        [0.3822, 0.4857],\n",
            "        [0.3823, 0.4729],\n",
            "        [0.3750, 0.4732],\n",
            "        [0.3540, 0.4495],\n",
            "        [0.3955, 0.4664],\n",
            "        [0.3528, 0.4238],\n",
            "        [0.3812, 0.4511],\n",
            "        [0.3541, 0.4506],\n",
            "        [0.3687, 0.4687],\n",
            "        [0.3511, 0.4395],\n",
            "        [0.3687, 0.4669],\n",
            "        [0.3643, 0.4616],\n",
            "        [0.3585, 0.4950],\n",
            "        [0.3368, 0.4701],\n",
            "        [0.3785, 0.4438],\n",
            "        [0.3681, 0.4716],\n",
            "        [0.3255, 0.4751],\n",
            "        [0.3797, 0.4400],\n",
            "        [0.3684, 0.4723],\n",
            "        [0.3745, 0.4591],\n",
            "        [0.3830, 0.4615],\n",
            "        [0.3524, 0.4475],\n",
            "        [0.3704, 0.4691],\n",
            "        [0.3684, 0.4446],\n",
            "        [0.3572, 0.4609],\n",
            "        [0.3424, 0.4953],\n",
            "        [0.3439, 0.5037],\n",
            "        [0.3681, 0.4694],\n",
            "        [0.3566, 0.4155],\n",
            "        [0.3830, 0.4601],\n",
            "        [0.3727, 0.4711],\n",
            "        [0.3580, 0.4785],\n",
            "        [0.3736, 0.4703],\n",
            "        [0.3825, 0.4515],\n",
            "        [0.3553, 0.4502],\n",
            "        [0.3537, 0.4485],\n",
            "        [0.3634, 0.4115],\n",
            "        [0.3494, 0.4596],\n",
            "        [0.3726, 0.4669],\n",
            "        [0.3777, 0.4552],\n",
            "        [0.3704, 0.4655],\n",
            "        [0.3707, 0.4724],\n",
            "        [0.3533, 0.4506],\n",
            "        [0.3563, 0.4536],\n",
            "        [0.3070, 0.4978],\n",
            "        [0.3635, 0.4560],\n",
            "        [0.3615, 0.5010],\n",
            "        [0.3889, 0.4442],\n",
            "        [0.3730, 0.4659],\n",
            "        [0.3535, 0.4511],\n",
            "        [0.3963, 0.4719],\n",
            "        [0.3697, 0.4714],\n",
            "        [0.3538, 0.4493],\n",
            "        [0.3553, 0.4502],\n",
            "        [0.3475, 0.4575],\n",
            "        [0.3750, 0.4493],\n",
            "        [0.3538, 0.4505],\n",
            "        [0.3823, 0.4641],\n",
            "        [0.3312, 0.4448],\n",
            "        [0.3640, 0.4609]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
            "Loss: 0.7103176116943359 ,Train accuracy: 0.51171875\n",
            "Loss: 0.7077020406723022 ,Train accuracy: 0.51953125\n",
            "Loss: 0.7028015851974487 ,Train accuracy: 0.49609375\n",
            "Loss: 0.6817879676818848 ,Train accuracy: 0.7578125\n",
            "Loss: 0.6854248642921448 ,Train accuracy: 0.5078125\n",
            "Loss: 0.6753628849983215 ,Train accuracy: 0.51953125\n",
            "Loss: 0.6838704347610474 ,Train accuracy: 0.51171875\n",
            "Loss: 0.6728823781013489 ,Train accuracy: 0.55859375\n",
            "Loss: 0.7080448865890503 ,Train accuracy: 0.44921875\n",
            "Loss: 0.6016685962677002 ,Train accuracy: 0.6640625\n",
            "Loss: 0.6262301802635193 ,Train accuracy: 0.75\n",
            "Loss: 0.6218240261077881 ,Train accuracy: 0.8515625\n",
            "Loss: 0.6359854936599731 ,Train accuracy: 0.8125\n",
            "Loss: 0.6015794277191162 ,Train accuracy: 0.8125\n",
            "Loss: 0.614544153213501 ,Train accuracy: 0.79296875\n",
            "Loss: 0.607441782951355 ,Train accuracy: 0.80078125\n",
            "Loss: 0.5987750291824341 ,Train accuracy: 0.8125\n",
            "Loss: 0.6615151762962341 ,Train accuracy: 0.765625\n",
            "Loss: 0.552579402923584 ,Train accuracy: 0.83203125\n",
            "Loss: 0.5364428758621216 ,Train accuracy: 0.80078125\n",
            "Loss: 0.5302817821502686 ,Train accuracy: 0.82421875\n",
            "Loss: 0.5371535420417786 ,Train accuracy: 0.8515625\n",
            "Loss: 0.4846554100513458 ,Train accuracy: 0.87109375\n",
            "Loss: 0.49879980087280273 ,Train accuracy: 0.8125\n",
            "Loss: 0.47105535864830017 ,Train accuracy: 0.86328125\n",
            "Loss: 0.4943804144859314 ,Train accuracy: 0.84375\n",
            "Loss: 0.5623419880867004 ,Train accuracy: 0.828125\n",
            "Loss: 0.4642666280269623 ,Train accuracy: 0.83984375\n",
            "Loss: 0.42350125312805176 ,Train accuracy: 0.83984375\n",
            "Loss: 0.4070143699645996 ,Train accuracy: 0.90625\n",
            "Loss: 0.3759791851043701 ,Train accuracy: 0.921875\n",
            "Loss: 0.35306018590927124 ,Train accuracy: 0.9140625\n",
            "Loss: 0.3494531512260437 ,Train accuracy: 0.91796875\n",
            "Loss: 0.3055460751056671 ,Train accuracy: 0.94921875\n",
            "Loss: 0.34167319536209106 ,Train accuracy: 0.88671875\n",
            "Loss: 0.3872040808200836 ,Train accuracy: 0.890625\n",
            "Loss: 0.2984640300273895 ,Train accuracy: 0.91015625\n",
            "Loss: 0.2847839295864105 ,Train accuracy: 0.8984375\n",
            "Loss: 0.2644350528717041 ,Train accuracy: 0.94921875\n",
            "Loss: 0.22133766114711761 ,Train accuracy: 0.96484375\n",
            "Loss: 0.20315584540367126 ,Train accuracy: 0.96484375\n",
            "Loss: 0.20618250966072083 ,Train accuracy: 0.953125\n",
            "Loss: 0.16776078939437866 ,Train accuracy: 0.96875\n",
            "Loss: 0.19087491929531097 ,Train accuracy: 0.9375\n",
            "Loss: 0.20321668684482574 ,Train accuracy: 0.95703125\n",
            "Loss: 0.1602131724357605 ,Train accuracy: 0.96875\n",
            "Loss: 0.14990705251693726 ,Train accuracy: 0.94921875\n",
            "Loss: 0.14726024866104126 ,Train accuracy: 0.984375\n",
            "Loss: 0.1276320070028305 ,Train accuracy: 0.9921875\n",
            "Loss: 0.11040063947439194 ,Train accuracy: 0.9921875\n",
            "Loss: 0.11909287422895432 ,Train accuracy: 0.984375\n",
            "Loss: 0.08504533022642136 ,Train accuracy: 1.0\n",
            "Loss: 0.09405777603387833 ,Train accuracy: 0.9921875\n",
            "Loss: 0.10472416877746582 ,Train accuracy: 0.984375\n",
            "Loss: 0.08355476707220078 ,Train accuracy: 0.9921875\n",
            "Loss: 0.08405520766973495 ,Train accuracy: 0.9765625\n",
            "Loss: 0.07656562328338623 ,Train accuracy: 0.9921875\n",
            "Loss: 0.0777495875954628 ,Train accuracy: 0.9921875\n",
            "Loss: 0.06798997521400452 ,Train accuracy: 1.0\n",
            "Loss: 0.07080709934234619 ,Train accuracy: 0.9921875\n",
            "Loss: 0.04464304447174072 ,Train accuracy: 1.0\n",
            "Loss: 0.05631266161799431 ,Train accuracy: 1.0\n",
            "Loss: 0.06722329556941986 ,Train accuracy: 0.9921875\n",
            "Loss: 0.05176397040486336 ,Train accuracy: 0.99609375\n",
            "Loss: 0.04465522617101669 ,Train accuracy: 1.0\n",
            "Loss: 0.04491019248962402 ,Train accuracy: 1.0\n",
            "Loss: 0.04602176696062088 ,Train accuracy: 0.9921875\n",
            "Loss: 0.03924386948347092 ,Train accuracy: 1.0\n",
            "Loss: 0.04975317418575287 ,Train accuracy: 0.9921875\n",
            "Loss: 0.029162803664803505 ,Train accuracy: 1.0\n",
            "Loss: 0.039223428815603256 ,Train accuracy: 1.0\n",
            "Loss: 0.04460207372903824 ,Train accuracy: 0.9921875\n",
            "Loss: 0.03210707753896713 ,Train accuracy: 1.0\n",
            "Loss: 0.02660386450588703 ,Train accuracy: 1.0\n",
            "Loss: 0.03131363168358803 ,Train accuracy: 1.0\n",
            "Loss: 0.03449302539229393 ,Train accuracy: 1.0\n",
            "Loss: 0.02684938535094261 ,Train accuracy: 1.0\n",
            "Loss: 0.03283769637346268 ,Train accuracy: 0.9921875\n",
            "Loss: 0.019027508795261383 ,Train accuracy: 1.0\n",
            "Loss: 0.02371983975172043 ,Train accuracy: 1.0\n",
            "Loss: 0.028544940054416656 ,Train accuracy: 1.0\n",
            "Loss: 0.01932607963681221 ,Train accuracy: 1.0\n",
            "Loss: 0.019622333347797394 ,Train accuracy: 1.0\n",
            "Loss: 0.024175060912966728 ,Train accuracy: 1.0\n",
            "Loss: 0.02246253378689289 ,Train accuracy: 1.0\n",
            "Loss: 0.017739277333021164 ,Train accuracy: 1.0\n",
            "Loss: 0.021381720900535583 ,Train accuracy: 0.9921875\n",
            "Loss: 0.013453459367156029 ,Train accuracy: 1.0\n",
            "Loss: 0.017901312559843063 ,Train accuracy: 1.0\n",
            "Loss: 0.01908905990421772 ,Train accuracy: 1.0\n",
            "Loss: 0.014432640746235847 ,Train accuracy: 1.0\n",
            "Loss: 0.014145532622933388 ,Train accuracy: 1.0\n",
            "Loss: 0.017430029809474945 ,Train accuracy: 1.0\n",
            "Loss: 0.015991782769560814 ,Train accuracy: 1.0\n",
            "Loss: 0.01346990279853344 ,Train accuracy: 1.0\n",
            "Loss: 0.014497078955173492 ,Train accuracy: 1.0\n",
            "Loss: 0.009991621598601341 ,Train accuracy: 1.0\n",
            "Loss: 0.013040078803896904 ,Train accuracy: 1.0\n",
            "Loss: 0.01395696122199297 ,Train accuracy: 1.0\n",
            "Loss: 0.009799869731068611 ,Train accuracy: 1.0\n",
            "Loss: 0.010274562984704971 ,Train accuracy: 1.0\n",
            "Loss: 0.009934164583683014 ,Train accuracy: 1.0\n",
            "Loss: 0.011276526376605034 ,Train accuracy: 1.0\n",
            "Loss: 0.009644091129302979 ,Train accuracy: 1.0\n",
            "Loss: 0.010917749255895615 ,Train accuracy: 1.0\n",
            "Loss: 0.0074402568861842155 ,Train accuracy: 1.0\n",
            "Loss: 0.009404436685144901 ,Train accuracy: 1.0\n",
            "Loss: 0.010420645587146282 ,Train accuracy: 1.0\n",
            "Loss: 0.007571257650852203 ,Train accuracy: 1.0\n",
            "Loss: 0.00756825739517808 ,Train accuracy: 1.0\n",
            "Loss: 0.007584961596876383 ,Train accuracy: 1.0\n",
            "Loss: 0.008755534887313843 ,Train accuracy: 1.0\n",
            "Loss: 0.007679395377635956 ,Train accuracy: 1.0\n",
            "Loss: 0.008824031800031662 ,Train accuracy: 1.0\n",
            "Loss: 0.006082912441343069 ,Train accuracy: 1.0\n",
            "Loss: 0.006920464802533388 ,Train accuracy: 1.0\n",
            "Loss: 0.008037650026381016 ,Train accuracy: 1.0\n",
            "Loss: 0.005948526319116354 ,Train accuracy: 1.0\n",
            "Loss: 0.006115440279245377 ,Train accuracy: 1.0\n",
            "Loss: 0.006276820786297321 ,Train accuracy: 1.0\n",
            "Loss: 0.006735336966812611 ,Train accuracy: 1.0\n",
            "Loss: 0.005997328087687492 ,Train accuracy: 1.0\n",
            "Loss: 0.007182057481259108 ,Train accuracy: 1.0\n",
            "Loss: 0.005004946608096361 ,Train accuracy: 1.0\n",
            "Loss: 0.005243794992566109 ,Train accuracy: 1.0\n",
            "Loss: 0.006850250530987978 ,Train accuracy: 1.0\n",
            "Loss: 0.004924974404275417 ,Train accuracy: 1.0\n",
            "Loss: 0.004766573663800955 ,Train accuracy: 1.0\n",
            "Loss: 0.005075397435575724 ,Train accuracy: 1.0\n",
            "Loss: 0.00547294644638896 ,Train accuracy: 1.0\n",
            "Loss: 0.00488674221560359 ,Train accuracy: 1.0\n",
            "Loss: 0.005931091494858265 ,Train accuracy: 1.0\n",
            "Loss: 0.00409833574667573 ,Train accuracy: 1.0\n",
            "Loss: 0.004369385540485382 ,Train accuracy: 1.0\n",
            "Loss: 0.00557240005582571 ,Train accuracy: 1.0\n",
            "Loss: 0.00417975103482604 ,Train accuracy: 1.0\n",
            "Loss: 0.003955774940550327 ,Train accuracy: 1.0\n",
            "Loss: 0.004232044331729412 ,Train accuracy: 1.0\n",
            "Loss: 0.004532500170171261 ,Train accuracy: 1.0\n",
            "Loss: 0.0040741185657680035 ,Train accuracy: 1.0\n",
            "Loss: 0.005043036304414272 ,Train accuracy: 1.0\n",
            "Loss: 0.003375223372131586 ,Train accuracy: 1.0\n",
            "Loss: 0.0036437390372157097 ,Train accuracy: 1.0\n",
            "Loss: 0.00450019259005785 ,Train accuracy: 1.0\n",
            "Loss: 0.0035510906018316746 ,Train accuracy: 1.0\n",
            "Loss: 0.003293619491159916 ,Train accuracy: 1.0\n",
            "Loss: 0.00357248866930604 ,Train accuracy: 1.0\n",
            "Loss: 0.003813273971900344 ,Train accuracy: 1.0\n",
            "Loss: 0.003453027456998825 ,Train accuracy: 1.0\n",
            "Loss: 0.00440911203622818 ,Train accuracy: 1.0\n",
            "Loss: 0.0028320327401161194 ,Train accuracy: 1.0\n",
            "Loss: 0.003106584306806326 ,Train accuracy: 1.0\n",
            "Loss: 0.0037446487694978714 ,Train accuracy: 1.0\n",
            "Loss: 0.0030280756764113903 ,Train accuracy: 1.0\n",
            "Loss: 0.002800465328618884 ,Train accuracy: 1.0\n",
            "Loss: 0.0030287555418908596 ,Train accuracy: 1.0\n",
            "Loss: 0.003254308830946684 ,Train accuracy: 1.0\n",
            "Loss: 0.0029495093040168285 ,Train accuracy: 1.0\n",
            "Loss: 0.003779554506763816 ,Train accuracy: 1.0\n",
            "Loss: 0.0024135757703334093 ,Train accuracy: 1.0\n",
            "Loss: 0.00266769016161561 ,Train accuracy: 1.0\n",
            "Loss: 0.0031643109396100044 ,Train accuracy: 1.0\n",
            "Loss: 0.002585765440016985 ,Train accuracy: 1.0\n",
            "Loss: 0.0024066930636763573 ,Train accuracy: 1.0\n",
            "Loss: 0.002594634657725692 ,Train accuracy: 1.0\n",
            "Loss: 0.002808674704283476 ,Train accuracy: 1.0\n",
            "Loss: 0.0025376540143042803 ,Train accuracy: 1.0\n",
            "Loss: 0.003059591632336378 ,Train accuracy: 1.0\n",
            "Loss: 0.0020775601733475924 ,Train accuracy: 1.0\n",
            "Loss: 0.002304574940353632 ,Train accuracy: 1.0\n",
            "Loss: 0.002700208220630884 ,Train accuracy: 1.0\n",
            "Loss: 0.002209319733083248 ,Train accuracy: 1.0\n",
            "Loss: 0.0020814575254917145 ,Train accuracy: 1.0\n",
            "Loss: 0.0022436322178691626 ,Train accuracy: 1.0\n",
            "Loss: 0.002437128219753504 ,Train accuracy: 1.0\n",
            "Loss: 0.002193354768678546 ,Train accuracy: 1.0\n",
            "Loss: 0.0023954357020556927 ,Train accuracy: 1.0\n",
            "Loss: 0.0017976630479097366 ,Train accuracy: 1.0\n",
            "Loss: 0.0020023109391331673 ,Train accuracy: 1.0\n",
            "Loss: 0.0023291734978556633 ,Train accuracy: 1.0\n",
            "Loss: 0.0018993219127878547 ,Train accuracy: 1.0\n",
            "Loss: 0.0018103329930454493 ,Train accuracy: 1.0\n",
            "Loss: 0.0019513643346726894 ,Train accuracy: 1.0\n",
            "Loss: 0.00212043896317482 ,Train accuracy: 1.0\n",
            "Loss: 0.0019053936703130603 ,Train accuracy: 1.0\n",
            "Loss: 0.002062071580439806 ,Train accuracy: 1.0\n",
            "Loss: 0.0015695428010076284 ,Train accuracy: 1.0\n",
            "Loss: 0.0017483343835920095 ,Train accuracy: 1.0\n",
            "Loss: 0.0020254163537174463 ,Train accuracy: 1.0\n",
            "Loss: 0.0016423809574916959 ,Train accuracy: 1.0\n",
            "Loss: 0.0015801968984305859 ,Train accuracy: 1.0\n",
            "Loss: 0.0017073660856112838 ,Train accuracy: 1.0\n",
            "Loss: 0.0018510868540033698 ,Train accuracy: 1.0\n",
            "Loss: 0.0016604237025603652 ,Train accuracy: 1.0\n",
            "Loss: 0.0018062915187329054 ,Train accuracy: 1.0\n",
            "Loss: 0.0013768026838079095 ,Train accuracy: 1.0\n",
            "Loss: 0.001533888978883624 ,Train accuracy: 1.0\n",
            "Loss: 0.0017684240592643619 ,Train accuracy: 1.0\n",
            "Loss: 0.0014309508260339499 ,Train accuracy: 1.0\n",
            "Loss: 0.0013858610764145851 ,Train accuracy: 1.0\n",
            "Loss: 0.0015012604417279363 ,Train accuracy: 1.0\n",
            "Loss: 0.0016229404136538506 ,Train accuracy: 1.0\n",
            "Loss: 0.001453154836781323 ,Train accuracy: 1.0\n",
            "Loss: 0.0015911813825368881 ,Train accuracy: 1.0\n",
            "Loss: 0.0012121277395635843 ,Train accuracy: 1.0\n",
            "Loss: 0.00135059654712677 ,Train accuracy: 1.0\n",
            "Loss: 0.0015520001761615276 ,Train accuracy: 1.0\n",
            "Loss: 0.0012539728777483106 ,Train accuracy: 1.0\n",
            "Loss: 0.0012201552744954824 ,Train accuracy: 1.0\n",
            "Loss: 0.001327351201325655 ,Train accuracy: 1.0\n",
            "Loss: 0.0014273578999564052 ,Train accuracy: 1.0\n",
            "Loss: 0.001276256749406457 ,Train accuracy: 1.0\n",
            "Loss: 0.0013963140081614256 ,Train accuracy: 1.0\n",
            "Loss: 0.001070334343239665 ,Train accuracy: 1.0\n",
            "Loss: 0.001193705014884472 ,Train accuracy: 1.0\n",
            "Loss: 0.0013676711823791265 ,Train accuracy: 1.0\n",
            "Loss: 0.0011040857061743736 ,Train accuracy: 1.0\n",
            "Loss: 0.0010782098397612572 ,Train accuracy: 1.0\n",
            "Loss: 0.0011793849989771843 ,Train accuracy: 1.0\n",
            "Loss: 0.0012577513698488474 ,Train accuracy: 1.0\n",
            "Loss: 0.0011241177562624216 ,Train accuracy: 1.0\n",
            "Loss: 0.001213874900713563 ,Train accuracy: 1.0\n",
            "Loss: 0.0009473446989431977 ,Train accuracy: 1.0\n",
            "Loss: 0.0010573496110737324 ,Train accuracy: 1.0\n",
            "Loss: 0.0012083039619028568 ,Train accuracy: 1.0\n",
            "Loss: 0.0009761248948052526 ,Train accuracy: 1.0\n",
            "Loss: 0.0009561232291162014 ,Train accuracy: 1.0\n",
            "Loss: 0.0010494934394955635 ,Train accuracy: 1.0\n",
            "Loss: 0.0011126763420179486 ,Train accuracy: 1.0\n",
            "Loss: 0.0009924955666065216 ,Train accuracy: 1.0\n",
            "Loss: 0.0010551030281931162 ,Train accuracy: 1.0\n",
            "Loss: 0.0008400048827752471 ,Train accuracy: 1.0\n",
            "Loss: 0.0009390975465066731 ,Train accuracy: 1.0\n",
            "Loss: 0.001070697559043765 ,Train accuracy: 1.0\n",
            "Loss: 0.0008660174207761884 ,Train accuracy: 1.0\n",
            "Loss: 0.0008501519914716482 ,Train accuracy: 1.0\n",
            "Loss: 0.0009350904729217291 ,Train accuracy: 1.0\n",
            "Loss: 0.0009879046119749546 ,Train accuracy: 1.0\n",
            "Loss: 0.0008783841039985418 ,Train accuracy: 1.0\n",
            "Loss: 0.0009330552420578897 ,Train accuracy: 1.0\n",
            "Loss: 0.0007468810654245317 ,Train accuracy: 1.0\n",
            "Loss: 0.0008357667829841375 ,Train accuracy: 1.0\n",
            "Loss: 0.0009511979878880084 ,Train accuracy: 1.0\n",
            "Loss: 0.0007703889859840274 ,Train accuracy: 1.0\n",
            "Loss: 0.0007576480857096612 ,Train accuracy: 1.0\n",
            "Loss: 0.0008342590881511569 ,Train accuracy: 1.0\n",
            "Loss: 0.000879839644767344 ,Train accuracy: 1.0\n",
            "Loss: 0.0007794731063768268 ,Train accuracy: 1.0\n",
            "Loss: 0.0008341382490471005 ,Train accuracy: 1.0\n",
            "Loss: 0.0006658786442130804 ,Train accuracy: 1.0\n",
            "Loss: 0.0007451499113813043 ,Train accuracy: 1.0\n",
            "Loss: 0.000846787472255528 ,Train accuracy: 1.0\n",
            "Loss: 0.0006868526106700301 ,Train accuracy: 1.0\n",
            "Loss: 0.0006765714497305453 ,Train accuracy: 1.0\n",
            "Loss: 0.0007454562000930309 ,Train accuracy: 1.0\n",
            "Loss: 0.0007861822959966958 ,Train accuracy: 1.0\n",
            "Loss: 0.0006934747798368335 ,Train accuracy: 1.0\n",
            "Loss: 0.0007478502229787409 ,Train accuracy: 1.0\n",
            "Loss: 0.0005948360194452107 ,Train accuracy: 1.0\n",
            "Loss: 0.000665677769575268 ,Train accuracy: 1.0\n",
            "Loss: 0.0007550452137365937 ,Train accuracy: 1.0\n",
            "Loss: 0.0006136844167485833 ,Train accuracy: 1.0\n",
            "Loss: 0.0006053539691492915 ,Train accuracy: 1.0\n",
            "Loss: 0.0006671249866485596 ,Train accuracy: 1.0\n",
            "Loss: 0.0007042912184260786 ,Train accuracy: 1.0\n",
            "Loss: 0.000618392659816891 ,Train accuracy: 1.0\n",
            "Loss: 0.0006707991124130785 ,Train accuracy: 1.0\n",
            "Loss: 0.0005320023046806455 ,Train accuracy: 1.0\n",
            "Loss: 0.0005958323599770665 ,Train accuracy: 1.0\n",
            "Loss: 0.0006741749821230769 ,Train accuracy: 1.0\n",
            "Loss: 0.0005493901553563774 ,Train accuracy: 1.0\n",
            "Loss: 0.0005426318384706974 ,Train accuracy: 1.0\n",
            "Loss: 0.0005978142144158483 ,Train accuracy: 1.0\n",
            "Loss: 0.0006318435771390796 ,Train accuracy: 1.0\n",
            "Loss: 0.0005527266184799373 ,Train accuracy: 1.0\n",
            "Loss: 0.0006016327533870935 ,Train accuracy: 1.0\n",
            "Loss: 0.00047640595585107803 ,Train accuracy: 1.0\n",
            "Loss: 0.000534170656464994 ,Train accuracy: 1.0\n",
            "Loss: 0.0006026843329891562 ,Train accuracy: 1.0\n",
            "Loss: 0.0004927110858261585 ,Train accuracy: 1.0\n",
            "Loss: 0.00048716686433181167 ,Train accuracy: 1.0\n",
            "Loss: 0.0005363888340070844 ,Train accuracy: 1.0\n",
            "Loss: 0.0005672042607329786 ,Train accuracy: 1.0\n",
            "Loss: 0.0004953286261297762 ,Train accuracy: 1.0\n",
            "Loss: 0.0005400213412940502 ,Train accuracy: 1.0\n",
            "Loss: 0.00042727880645543337 ,Train accuracy: 1.0\n",
            "Loss: 0.00047950836597010493 ,Train accuracy: 1.0\n",
            "Loss: 0.0005393075989559293 ,Train accuracy: 1.0\n",
            "Loss: 0.00044259551214054227 ,Train accuracy: 1.0\n",
            "Loss: 0.00043787015601992607 ,Train accuracy: 1.0\n",
            "Loss: 0.0004820235481020063 ,Train accuracy: 1.0\n",
            "Loss: 0.0005089995684102178 ,Train accuracy: 1.0\n",
            "Loss: 0.00044492987217381597 ,Train accuracy: 1.0\n",
            "Loss: 0.000485887547256425 ,Train accuracy: 1.0\n",
            "Loss: 0.0003838001284748316 ,Train accuracy: 1.0\n",
            "Loss: 0.0004309161158744246 ,Train accuracy: 1.0\n",
            "Loss: 0.00048304026131518185 ,Train accuracy: 1.0\n",
            "Loss: 0.00039818757795728743 ,Train accuracy: 1.0\n",
            "Loss: 0.0003938256995752454 ,Train accuracy: 1.0\n",
            "Loss: 0.00043373621883802116 ,Train accuracy: 1.0\n",
            "Loss: 0.00045630824752151966 ,Train accuracy: 1.0\n",
            "Loss: 0.00040032179094851017 ,Train accuracy: 1.0\n",
            "Loss: 0.0004388017114251852 ,Train accuracy: 1.0\n",
            "Loss: 0.00034520580084063113 ,Train accuracy: 1.0\n",
            "Loss: 0.0003875891852658242 ,Train accuracy: 1.0\n",
            "Loss: 0.0004330128722358495 ,Train accuracy: 1.0\n",
            "Loss: 0.00035870171268470585 ,Train accuracy: 1.0\n",
            "Loss: 0.0003543291240930557 ,Train accuracy: 1.0\n",
            "Loss: 0.00039073702646419406 ,Train accuracy: 1.0\n",
            "Loss: 0.00040907348738983274 ,Train accuracy: 1.0\n",
            "Loss: 0.00036070222267881036 ,Train accuracy: 1.0\n",
            "Loss: 0.0003975146682932973 ,Train accuracy: 1.0\n",
            "Loss: 0.00031083132489584386 ,Train accuracy: 1.0\n",
            "Loss: 0.0003488719812594354 ,Train accuracy: 1.0\n",
            "Loss: 0.00038861215580254793 ,Train accuracy: 1.0\n",
            "Loss: 0.0003234444884583354 ,Train accuracy: 1.0\n",
            "Loss: 0.00031891578692011535 ,Train accuracy: 1.0\n",
            "Loss: 0.0003523969207890332 ,Train accuracy: 1.0\n",
            "Loss: 0.00036743131931871176 ,Train accuracy: 1.0\n",
            "Loss: 0.00032528460724279284 ,Train accuracy: 1.0\n",
            "Loss: 0.0003608266997616738 ,Train accuracy: 1.0\n",
            "Loss: 0.0002801011432893574 ,Train accuracy: 1.0\n",
            "Loss: 0.0003142436617054045 ,Train accuracy: 1.0\n",
            "Loss: 0.0003492684045340866 ,Train accuracy: 1.0\n",
            "Loss: 0.0002918235841207206 ,Train accuracy: 1.0\n",
            "Loss: 0.0002871839387807995 ,Train accuracy: 1.0\n",
            "Loss: 0.00031809075153432786 ,Train accuracy: 1.0\n",
            "Loss: 0.00033118054852820933 ,Train accuracy: 1.0\n",
            "Loss: 0.00029332388658076525 ,Train accuracy: 1.0\n",
            "Loss: 0.00032795482547953725 ,Train accuracy: 1.0\n",
            "Loss: 0.0002525377203710377 ,Train accuracy: 1.0\n",
            "Loss: 0.0002833486068993807 ,Train accuracy: 1.0\n",
            "Loss: 0.00031434145057573915 ,Train accuracy: 1.0\n",
            "Loss: 0.0002633637632243335 ,Train accuracy: 1.0\n",
            "Loss: 0.0002588024362921715 ,Train accuracy: 1.0\n",
            "Loss: 0.0002872939803637564 ,Train accuracy: 1.0\n",
            "Loss: 0.0002992372610606253 ,Train accuracy: 1.0\n",
            "Loss: 0.0002643035550136119 ,Train accuracy: 1.0\n",
            "Loss: 0.0002984816674143076 ,Train accuracy: 1.0\n",
            "Loss: 0.00022785851615481079 ,Train accuracy: 1.0\n",
            "Loss: 0.0002558262785896659 ,Train accuracy: 1.0\n",
            "Loss: 0.000283150642644614 ,Train accuracy: 1.0\n",
            "Loss: 0.00023803535441402346 ,Train accuracy: 1.0\n",
            "Loss: 0.00023385556414723396 ,Train accuracy: 1.0\n",
            "Loss: 0.00025971548166126013 ,Train accuracy: 1.0\n",
            "Loss: 0.0002705198130570352 ,Train accuracy: 1.0\n",
            "Loss: 0.00023815235181245953 ,Train accuracy: 1.0\n",
            "Loss: 0.0002721016062423587 ,Train accuracy: 1.0\n",
            "Loss: 0.00020583825244102627 ,Train accuracy: 1.0\n",
            "Loss: 0.00023102384875528514 ,Train accuracy: 1.0\n",
            "Loss: 0.00025514248409308493 ,Train accuracy: 1.0\n",
            "Loss: 0.00021543828188441694 ,Train accuracy: 1.0\n",
            "Loss: 0.00021117134019732475 ,Train accuracy: 1.0\n",
            "Loss: 0.0002349041315028444 ,Train accuracy: 1.0\n",
            "Loss: 0.00024484278401359916 ,Train accuracy: 1.0\n",
            "Loss: 0.00021499163995031267 ,Train accuracy: 1.0\n",
            "Loss: 0.0002483408898115158 ,Train accuracy: 1.0\n",
            "Loss: 0.00018602414638735354 ,Train accuracy: 1.0\n",
            "Loss: 0.00020890285668428987 ,Train accuracy: 1.0\n",
            "Loss: 0.00023017401690594852 ,Train accuracy: 1.0\n",
            "Loss: 0.00019520217028912157 ,Train accuracy: 1.0\n",
            "Loss: 0.00019078297191299498 ,Train accuracy: 1.0\n",
            "Loss: 0.00021263724192976952 ,Train accuracy: 1.0\n",
            "Loss: 0.00022186418937053531 ,Train accuracy: 1.0\n",
            "Loss: 0.00019457697635516524 ,Train accuracy: 1.0\n",
            "Loss: 0.00022689629986416548 ,Train accuracy: 1.0\n",
            "Loss: 0.00016823169426061213 ,Train accuracy: 1.0\n",
            "Loss: 0.00018909497885033488 ,Train accuracy: 1.0\n",
            "Loss: 0.00020783334912266582 ,Train accuracy: 1.0\n",
            "Loss: 0.00017704605124890804 ,Train accuracy: 1.0\n",
            "Loss: 0.00017258423031307757 ,Train accuracy: 1.0\n",
            "Loss: 0.00019262396381236613 ,Train accuracy: 1.0\n",
            "Loss: 0.00020119012333452702 ,Train accuracy: 1.0\n",
            "Loss: 0.00017640815349295735 ,Train accuracy: 1.0\n",
            "Loss: 0.0002074294025078416 ,Train accuracy: 1.0\n",
            "Loss: 0.00015229340351652354 ,Train accuracy: 1.0\n",
            "Loss: 0.00017122839926742017 ,Train accuracy: 1.0\n",
            "Loss: 0.00018754509801510721 ,Train accuracy: 1.0\n",
            "Loss: 0.00016065608360804617 ,Train accuracy: 1.0\n",
            "Loss: 0.0001563786354381591 ,Train accuracy: 1.0\n",
            "Loss: 0.00017452200700063258 ,Train accuracy: 1.0\n",
            "Loss: 0.00018235191237181425 ,Train accuracy: 1.0\n",
            "Loss: 0.00016013599815778434 ,Train accuracy: 1.0\n",
            "Loss: 0.00018973216356243938 ,Train accuracy: 1.0\n",
            "Loss: 0.00013785531336907297 ,Train accuracy: 1.0\n",
            "Loss: 0.0001551165769342333 ,Train accuracy: 1.0\n",
            "Loss: 0.00016938537009991705 ,Train accuracy: 1.0\n",
            "Loss: 0.00014587899204343557 ,Train accuracy: 1.0\n",
            "Loss: 0.00014192229718901217 ,Train accuracy: 1.0\n",
            "Loss: 0.00015814622747711837 ,Train accuracy: 1.0\n",
            "Loss: 0.00016514354501850903 ,Train accuracy: 1.0\n",
            "Loss: 0.00014552162610925734 ,Train accuracy: 1.0\n",
            "Loss: 0.0001735157275106758 ,Train accuracy: 1.0\n",
            "Loss: 0.0001248235785169527 ,Train accuracy: 1.0\n",
            "Loss: 0.00014056598593015224 ,Train accuracy: 1.0\n",
            "Loss: 0.0001532730966573581 ,Train accuracy: 1.0\n",
            "Loss: 0.00013250584015622735 ,Train accuracy: 1.0\n",
            "Loss: 0.00012894791143480688 ,Train accuracy: 1.0\n",
            "Loss: 0.00014332009595818818 ,Train accuracy: 1.0\n",
            "Loss: 0.00014955592632759362 ,Train accuracy: 1.0\n",
            "Loss: 0.0001322879979852587 ,Train accuracy: 1.0\n",
            "Loss: 0.00015870193601585925 ,Train accuracy: 1.0\n",
            "Loss: 0.00011316248128423467 ,Train accuracy: 1.0\n",
            "Loss: 0.0001275152899324894 ,Train accuracy: 1.0\n",
            "Loss: 0.00013883094652555883 ,Train accuracy: 1.0\n",
            "Loss: 0.00012040154979331419 ,Train accuracy: 1.0\n",
            "Loss: 0.00011724683281499892 ,Train accuracy: 1.0\n",
            "Loss: 0.00012993025302421302 ,Train accuracy: 1.0\n",
            "Loss: 0.00013559691433329135 ,Train accuracy: 1.0\n",
            "Loss: 0.00012025592877762392 ,Train accuracy: 1.0\n",
            "Loss: 0.00014513422502204776 ,Train accuracy: 1.0\n",
            "Loss: 0.00010266967001371086 ,Train accuracy: 1.0\n",
            "Loss: 0.00011574914969969541 ,Train accuracy: 1.0\n",
            "Loss: 0.0001259044511243701 ,Train accuracy: 1.0\n",
            "Loss: 0.00010944785026367754 ,Train accuracy: 1.0\n",
            "Loss: 0.00010658882092684507 ,Train accuracy: 1.0\n",
            "Loss: 0.00011779752094298601 ,Train accuracy: 1.0\n",
            "Loss: 0.00012304866686463356 ,Train accuracy: 1.0\n",
            "Loss: 0.00010928801930276677 ,Train accuracy: 1.0\n",
            "Loss: 0.00013271530042402446 ,Train accuracy: 1.0\n",
            "Loss: 9.320276149082929e-05 ,Train accuracy: 1.0\n",
            "Loss: 0.0001051104482030496 ,Train accuracy: 1.0\n",
            "Loss: 0.00011428957805037498 ,Train accuracy: 1.0\n",
            "Loss: 9.94912552414462e-05 ,Train accuracy: 1.0\n",
            "Loss: 9.680442599346861e-05 ,Train accuracy: 1.0\n",
            "Loss: 0.00010682697757147253 ,Train accuracy: 1.0\n",
            "Loss: 0.0001117606952902861 ,Train accuracy: 1.0\n",
            "Loss: 9.926203347276896e-05 ,Train accuracy: 1.0\n",
            "Loss: 0.00012123602209612727 ,Train accuracy: 1.0\n",
            "Loss: 8.464457641821355e-05 ,Train accuracy: 1.0\n",
            "Loss: 9.54401766648516e-05 ,Train accuracy: 1.0\n",
            "Loss: 0.0001037939073285088 ,Train accuracy: 1.0\n",
            "Loss: 9.041557495947927e-05 ,Train accuracy: 1.0\n",
            "Loss: 8.799924398772418e-05 ,Train accuracy: 1.0\n",
            "Loss: 9.692234016256407e-05 ,Train accuracy: 1.0\n",
            "Loss: 0.0001016636670101434 ,Train accuracy: 1.0\n",
            "Loss: 9.024946484714746e-05 ,Train accuracy: 1.0\n",
            "Loss: 0.00011042536061722785 ,Train accuracy: 1.0\n",
            "Loss: 7.687602192163467e-05 ,Train accuracy: 1.0\n",
            "Loss: 8.673231059219688e-05 ,Train accuracy: 1.0\n",
            "Loss: 9.43643826758489e-05 ,Train accuracy: 1.0\n",
            "Loss: 8.220231393352151e-05 ,Train accuracy: 1.0\n",
            "Loss: 7.998204819159582e-05 ,Train accuracy: 1.0\n",
            "Loss: 8.787726983428001e-05 ,Train accuracy: 1.0\n",
            "Loss: 9.24963824218139e-05 ,Train accuracy: 1.0\n",
            "Loss: 8.205086487578228e-05 ,Train accuracy: 1.0\n",
            "Loss: 0.00010015761654358357 ,Train accuracy: 1.0\n",
            "Loss: 6.985836807871237e-05 ,Train accuracy: 1.0\n",
            "Loss: 7.873668801039457e-05 ,Train accuracy: 1.0\n",
            "Loss: 8.580152643844485e-05 ,Train accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(FCNN, criterion_FCNN, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3n_xRaZrrwa",
        "outputId": "99c744c2-69e2-41f2-af7a-33c3b28339e5"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.10503491759300232 ,Test accuracy: 0.9609375\n",
            "Loss: 0.3403957784175873 ,Test accuracy: 0.9296875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the trained weights"
      ],
      "metadata": {
        "id": "8j8UUsWIq4tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(FCNN.state_dict(), 'NeuralNetwork_weights_anti64.pth')"
      ],
      "metadata": {
        "id": "s7A28z4Cjrip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the trained weights"
      ],
      "metadata": {
        "id": "wCTl8j7YrBcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FCNN.load_state_dict(torch.load('model_weights.pth'))"
      ],
      "metadata": {
        "id": "p0d8eIZdtcjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN"
      ],
      "metadata": {
        "id": "ahyH_oUYpvUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential([\n",
        "#           layers.Reshape(target_shape=(40,40,1), input_shape=(40,40)),\n",
        "#           layers.Conv2D(128, (3,3), padding='valid', activation='relu'),\n",
        "#           layers.Flatten(),\n",
        "#           layers.Dense(128, activation='relu'),\n",
        "#           layers.Dropout(.5),\n",
        "#           layers.Dense(2, activation='softmax')\n",
        "#         ])\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, Nx, Ny):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # Equivalent to Reshape in Keras, but in PyTorch, reshaping is typically done in the forward method.\n",
        "        # Conv2D layer with 128 filters, kernel size of 3x3, padding='valid' implies no padding in PyTorch\n",
        "        self.conv1 = nn.Conv2d(1, 128, kernel_size=3, padding=0)\n",
        "        # Determine the output size of the first convolutional layer\n",
        "        out_conv1 = self._calculate_output_size((Nx, Ny), kernel_size=3, padding=0)\n",
        "        # Dense layer with 128 units\n",
        "        self.fc1 = nn.Linear(128 * out_conv1[0] * out_conv1[1], 128)\n",
        "        # Dropout layer with p=0.5\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        # Output Dense layer with 2 units for softmax output\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape input to have one channel\n",
        "        x = x.view(-1, 1, x.size(1), x.size(2))\n",
        "        # Applying Convolutional Layer\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # Flattening the output of the conv layer\n",
        "        x = self.flatten(x)     # ------------------\n",
        "        # Dense layer with ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # Output layer with softmax activation\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "    def _calculate_output_size(self, input_size, kernel_size, padding):\n",
        "        # Calculate output size after convolutional layer\n",
        "        out_size = [(input_size[0] - kernel_size + 2 * padding) + 1,\n",
        "                    (input_size[1] - kernel_size + 2 * padding) + 1]\n",
        "        return out_size\n"
      ],
      "metadata": {
        "id": "4eyt1PidREIM"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer='adam',\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['binary_accuracy'])\n",
        "CNN = ConvNet(Nx, Ny).to(device)\n",
        "criterion_CNN = nn.BCELoss()\n",
        "optimizer_CNN = optim.Adam(CNN.parameters(), lr=lr, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "qiEhnYvsrOcv"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(CNN, 10, criterion_CNN, optimizer_CNN, train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBQPkd7RsPuA",
        "outputId": "486bbbde-effe-4627-877b-2a561a72dd73"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4780, 0.5220],\n",
            "        [0.5543, 0.4457],\n",
            "        [0.5361, 0.4639],\n",
            "        [0.5466, 0.4534],\n",
            "        [0.4472, 0.5528],\n",
            "        [0.5058, 0.4942],\n",
            "        [0.5929, 0.4071],\n",
            "        [0.5377, 0.4623],\n",
            "        [0.5004, 0.4996],\n",
            "        [0.5794, 0.4206],\n",
            "        [0.5884, 0.4116],\n",
            "        [0.4986, 0.5014],\n",
            "        [0.5812, 0.4188],\n",
            "        [0.5103, 0.4897],\n",
            "        [0.5502, 0.4498],\n",
            "        [0.5014, 0.4986],\n",
            "        [0.5728, 0.4272],\n",
            "        [0.4188, 0.5812],\n",
            "        [0.5493, 0.4507],\n",
            "        [0.5012, 0.4988],\n",
            "        [0.5858, 0.4142],\n",
            "        [0.5213, 0.4787],\n",
            "        [0.5395, 0.4605],\n",
            "        [0.4668, 0.5332],\n",
            "        [0.5648, 0.4352],\n",
            "        [0.5160, 0.4840],\n",
            "        [0.6187, 0.3813],\n",
            "        [0.5667, 0.4333],\n",
            "        [0.4915, 0.5085],\n",
            "        [0.5721, 0.4279],\n",
            "        [0.6411, 0.3589],\n",
            "        [0.5707, 0.4293],\n",
            "        [0.5912, 0.4088],\n",
            "        [0.5270, 0.4730],\n",
            "        [0.6177, 0.3823],\n",
            "        [0.4824, 0.5176],\n",
            "        [0.5185, 0.4815],\n",
            "        [0.5136, 0.4864],\n",
            "        [0.4748, 0.5252],\n",
            "        [0.5156, 0.4844],\n",
            "        [0.5500, 0.4500],\n",
            "        [0.5041, 0.4959],\n",
            "        [0.4616, 0.5384],\n",
            "        [0.5486, 0.4514],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.4834, 0.5166],\n",
            "        [0.5004, 0.4996],\n",
            "        [0.5464, 0.4536],\n",
            "        [0.5418, 0.4582],\n",
            "        [0.4582, 0.5418],\n",
            "        [0.5672, 0.4328],\n",
            "        [0.4607, 0.5393],\n",
            "        [0.5152, 0.4848],\n",
            "        [0.6012, 0.3988],\n",
            "        [0.5645, 0.4355],\n",
            "        [0.5145, 0.4855],\n",
            "        [0.4748, 0.5252],\n",
            "        [0.5467, 0.4533],\n",
            "        [0.5439, 0.4561],\n",
            "        [0.5505, 0.4495],\n",
            "        [0.5590, 0.4410],\n",
            "        [0.5735, 0.4265],\n",
            "        [0.5191, 0.4809],\n",
            "        [0.5237, 0.4763],\n",
            "        [0.5105, 0.4895],\n",
            "        [0.5136, 0.4864],\n",
            "        [0.5900, 0.4100],\n",
            "        [0.4917, 0.5083],\n",
            "        [0.5612, 0.4388],\n",
            "        [0.5050, 0.4950],\n",
            "        [0.5655, 0.4345],\n",
            "        [0.5754, 0.4246],\n",
            "        [0.5689, 0.4311],\n",
            "        [0.5177, 0.4823],\n",
            "        [0.5768, 0.4232],\n",
            "        [0.5153, 0.4847],\n",
            "        [0.5694, 0.4306],\n",
            "        [0.4756, 0.5244],\n",
            "        [0.5284, 0.4716],\n",
            "        [0.5258, 0.4742],\n",
            "        [0.5465, 0.4535],\n",
            "        [0.5107, 0.4893],\n",
            "        [0.4625, 0.5375],\n",
            "        [0.5797, 0.4203],\n",
            "        [0.5180, 0.4820],\n",
            "        [0.5148, 0.4852],\n",
            "        [0.4974, 0.5026],\n",
            "        [0.5290, 0.4710],\n",
            "        [0.4902, 0.5098],\n",
            "        [0.6396, 0.3604],\n",
            "        [0.5736, 0.4264],\n",
            "        [0.6072, 0.3928],\n",
            "        [0.5287, 0.4713],\n",
            "        [0.5240, 0.4760],\n",
            "        [0.5455, 0.4545],\n",
            "        [0.5577, 0.4423],\n",
            "        [0.4717, 0.5283],\n",
            "        [0.4897, 0.5103],\n",
            "        [0.5219, 0.4781],\n",
            "        [0.4932, 0.5068],\n",
            "        [0.6575, 0.3425],\n",
            "        [0.5652, 0.4348],\n",
            "        [0.5190, 0.4810],\n",
            "        [0.5219, 0.4781],\n",
            "        [0.4753, 0.5247],\n",
            "        [0.5360, 0.4640],\n",
            "        [0.5355, 0.4645],\n",
            "        [0.4878, 0.5122],\n",
            "        [0.5638, 0.4362],\n",
            "        [0.6017, 0.3983],\n",
            "        [0.5165, 0.4835],\n",
            "        [0.4894, 0.5106],\n",
            "        [0.5940, 0.4060],\n",
            "        [0.5449, 0.4551],\n",
            "        [0.5928, 0.4072],\n",
            "        [0.5705, 0.4295],\n",
            "        [0.6087, 0.3913],\n",
            "        [0.5350, 0.4650],\n",
            "        [0.5644, 0.4356],\n",
            "        [0.5315, 0.4685],\n",
            "        [0.5053, 0.4947],\n",
            "        [0.5250, 0.4750],\n",
            "        [0.5017, 0.4983],\n",
            "        [0.5794, 0.4206],\n",
            "        [0.5328, 0.4672],\n",
            "        [0.4130, 0.5870],\n",
            "        [0.5042, 0.4958],\n",
            "        [0.4478, 0.5522]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Loss: 0.6927299499511719 ,Train accuracy: 0.5625\n",
            "Loss: 6.586808204650879 ,Train accuracy: 0.9140625\n",
            "Loss: 5.915210247039795 ,Train accuracy: 0.9296875\n",
            "Loss: 3.858910083770752 ,Train accuracy: 0.953125\n",
            "Loss: 8.48310375213623 ,Train accuracy: 0.90625\n",
            "Loss: 6.132816314697266 ,Train accuracy: 0.9375\n",
            "Loss: 9.863898277282715 ,Train accuracy: 0.8984375\n",
            "Loss: 33.5013542175293 ,Train accuracy: 0.6640625\n",
            "Loss: 21.65397834777832 ,Train accuracy: 0.7734375\n",
            "Loss: 11.325502395629883 ,Train accuracy: 0.875\n",
            "Loss: 13.75579833984375 ,Train accuracy: 0.859375\n",
            "Loss: 12.5 ,Train accuracy: 0.875\n",
            "Loss: 15.65298843383789 ,Train accuracy: 0.8359375\n",
            "Loss: 11.207741737365723 ,Train accuracy: 0.8828125\n",
            "Loss: 7.767677307128906 ,Train accuracy: 0.921875\n",
            "Loss: 24.377113342285156 ,Train accuracy: 0.7421875\n",
            "Loss: 36.13475799560547 ,Train accuracy: 0.6328125\n",
            "Loss: 40.625 ,Train accuracy: 0.59375\n",
            "Loss: 22.998611450195312 ,Train accuracy: 0.765625\n",
            "Loss: 27.897811889648438 ,Train accuracy: 0.71875\n",
            "Loss: 32.81250762939453 ,Train accuracy: 0.671875\n",
            "Loss: 30.46875 ,Train accuracy: 0.6953125\n",
            "Loss: 25.174015045166016 ,Train accuracy: 0.734375\n",
            "Loss: 24.16948699951172 ,Train accuracy: 0.7578125\n",
            "Loss: 17.655868530273438 ,Train accuracy: 0.8203125\n",
            "Loss: 24.04503631591797 ,Train accuracy: 0.7578125\n",
            "Loss: 15.646896362304688 ,Train accuracy: 0.8359375\n",
            "Loss: 19.221481323242188 ,Train accuracy: 0.8046875\n",
            "Loss: 25.78125 ,Train accuracy: 0.7421875\n",
            "Loss: 28.90625 ,Train accuracy: 0.7109375\n",
            "Loss: 31.93714141845703 ,Train accuracy: 0.6796875\n",
            "Loss: 27.34375 ,Train accuracy: 0.7265625\n",
            "Loss: 28.243526458740234 ,Train accuracy: 0.7109375\n",
            "Loss: 22.65625 ,Train accuracy: 0.7734375\n",
            "Loss: 24.21875 ,Train accuracy: 0.7578125\n",
            "Loss: 23.4375 ,Train accuracy: 0.765625\n",
            "Loss: 28.125 ,Train accuracy: 0.71875\n",
            "Loss: 27.34375 ,Train accuracy: 0.7265625\n",
            "Loss: 25.78125 ,Train accuracy: 0.7421875\n",
            "Loss: 21.011245727539062 ,Train accuracy: 0.7890625\n",
            "Loss: 23.95215606689453 ,Train accuracy: 0.7578125\n",
            "Loss: 21.681854248046875 ,Train accuracy: 0.78125\n",
            "Loss: 27.34375 ,Train accuracy: 0.7265625\n",
            "Loss: 28.125 ,Train accuracy: 0.71875\n",
            "Loss: 30.211280822753906 ,Train accuracy: 0.6953125\n",
            "Loss: 26.5625 ,Train accuracy: 0.734375\n",
            "Loss: 25.0 ,Train accuracy: 0.75\n",
            "Loss: 22.328582763671875 ,Train accuracy: 0.7734375\n",
            "Loss: 26.5625 ,Train accuracy: 0.734375\n",
            "Loss: 27.135269165039062 ,Train accuracy: 0.71875\n",
            "Loss: 28.125 ,Train accuracy: 0.71875\n",
            "Loss: 24.21875 ,Train accuracy: 0.7578125\n",
            "Loss: 34.375 ,Train accuracy: 0.65625\n",
            "Loss: 30.46875 ,Train accuracy: 0.6953125\n",
            "Loss: 31.25 ,Train accuracy: 0.6875\n",
            "Loss: 42.1875 ,Train accuracy: 0.578125\n",
            "Loss: 33.50860595703125 ,Train accuracy: 0.6640625\n",
            "Loss: 33.3521728515625 ,Train accuracy: 0.6640625\n",
            "Loss: 38.90234375 ,Train accuracy: 0.609375\n",
            "Loss: 37.5 ,Train accuracy: 0.625\n",
            "Loss: 43.75 ,Train accuracy: 0.5625\n",
            "Loss: 47.65625 ,Train accuracy: 0.5234375\n",
            "Loss: 51.5625 ,Train accuracy: 0.484375\n",
            "Loss: 50.78125 ,Train accuracy: 0.4921875\n",
            "Loss: 57.8125 ,Train accuracy: 0.421875\n",
            "Loss: 34.910186767578125 ,Train accuracy: 0.6484375\n",
            "Loss: 25.78125 ,Train accuracy: 0.7421875\n",
            "Loss: 28.125 ,Train accuracy: 0.71875\n",
            "Loss: 30.46875 ,Train accuracy: 0.6953125\n",
            "Loss: 43.75 ,Train accuracy: 0.5625\n",
            "Loss: 47.65625 ,Train accuracy: 0.5234375\n",
            "Loss: 42.262451171875 ,Train accuracy: 0.5703125\n",
            "Loss: 43.75 ,Train accuracy: 0.5625\n",
            "Loss: 52.912109375 ,Train accuracy: 0.46875\n",
            "Loss: 29.6875 ,Train accuracy: 0.703125\n",
            "Loss: 29.6875 ,Train accuracy: 0.703125\n",
            "Loss: 36.719017028808594 ,Train accuracy: 0.6328125\n",
            "Loss: 40.625 ,Train accuracy: 0.59375\n",
            "Loss: 42.96875 ,Train accuracy: 0.5703125\n",
            "Loss: 40.330970764160156 ,Train accuracy: 0.5859375\n",
            "Loss: 36.71875 ,Train accuracy: 0.6328125\n",
            "Loss: 40.625 ,Train accuracy: 0.59375\n",
            "Loss: 36.71875 ,Train accuracy: 0.6328125\n",
            "Loss: 34.375 ,Train accuracy: 0.65625\n",
            "Loss: 35.9375 ,Train accuracy: 0.640625\n",
            "Loss: 32.8125 ,Train accuracy: 0.671875\n",
            "Loss: 35.9375 ,Train accuracy: 0.640625\n",
            "Loss: 37.5 ,Train accuracy: 0.625\n",
            "Loss: 37.22088623046875 ,Train accuracy: 0.625\n",
            "Loss: 38.28125 ,Train accuracy: 0.6171875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(CNN, criterion_CNN, test_dataloader)"
      ],
      "metadata": {
        "id": "WOSpMELUtN7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = get_predictions(test_dataloader, CNN)\n",
        "plt.scatter(outputs, Y_test)"
      ],
      "metadata": {
        "id": "z4dt_1iszAkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Previous code"
      ],
      "metadata": {
        "id": "sXnoLyrUTSb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------------\n",
        "Write a code to evaluate the model, you may do so by adding evaluation related steps in the training loop as well.<br>\n",
        "Plot the graphs as required.<br>\n",
        "Plot the graph by testing the model on NNN case as well.<br>\n",
        "Code a CNN model and perform all the actions as performed on an neural network."
      ],
      "metadata": {
        "id": "9W3iZDGskNdQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpH37d3OZ5ee",
        "outputId": "51d82fd6-6f01-4c43-e210-58caab927f99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL1\n",
            "122/122 [==============================] - 4s 2ms/step - loss: 0.1936 - accuracy: 0.9279\n",
            "MODEL3\n",
            "122/122 [==============================] - 4s 2ms/step - loss: 0.1081 - accuracy: 0.9708\n",
            "MODEL4\n",
            "122/122 [==============================] - 4s 2ms/step - loss: 0.1187 - accuracy: 0.9697\n"
          ]
        }
      ],
      "source": [
        "print('MODEL1')\n",
        "model1 = keras.Sequential()\n",
        "model1 = neural(model1, X_train1, X_test1, y_train1, y_test1)\n",
        "print('MODEL3')\n",
        "model3 = keras.Sequential()\n",
        "model3 = neural(model3, X_train3, X_test3, y_train3, y_test3)\n",
        "print('MODEL4')\n",
        "model4 = keras.Sequential()\n",
        "model4 = neural(model4, X_train4, X_test4, y_train4, y_test4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SoVN2ljZ5ef",
        "outputId": "1429eff5-a274-4649-b257-57f48f156311"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "execution_count": 272,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot([10,20,30], [0.9279,0.9644, 0.9708])\n",
        "plt.scatter([10,20,30], [0.9279,0.9644, 0.9708])\n",
        "plt.xlabel('Lattice size')\n",
        "plt.ylabel('Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BADZ6t5TZ5ef"
      },
      "outputs": [],
      "source": [
        "def preds(model, X_test, size):\n",
        "    l = []\n",
        "\n",
        "#     print('PREDICTIONS:')\n",
        "    for i in range(1,size):\n",
        "#         print('i=',i)\n",
        "        l.append(model.predict(X_test[(i-1):(i)], verbose = 0))\n",
        "    l = np.array(l)\n",
        "\n",
        "    return l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s284mcL9Z5ef"
      },
      "outputs": [],
      "source": [
        "def sortIt(l, y):\n",
        "    size = l.shape[0]\n",
        "    a = np.zeros(size)\n",
        "    b = np.zeros(size)\n",
        "    l1 = np.zeros(size)\n",
        "    l2 = np.zeros(size)\n",
        "    for x in range(size):\n",
        "      a[x]=l[x][0][0]\n",
        "      b[x]=l[x][0][1]\n",
        "      l1[x]=y[x]\n",
        "\n",
        "    c = np.array([l1, a])\n",
        "    sorted_c = c.T[l1.argsort()]\n",
        "\n",
        "    d = np.array([l1, b])\n",
        "    sorted_d = d.T[l1.argsort()]\n",
        "\n",
        "    return sorted_c, sorted_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr-CIgUaZ5ef"
      },
      "outputs": [],
      "source": [
        "def plotIt(sorted, y_test, yes=True):\n",
        "\n",
        "    t = np.arange(1, 3.51, 0.1)\n",
        "    vals = np.zeros(t.shape[0])\n",
        "    x_axisc = sorted[:,0]\n",
        "    y_axis = sorted[:,1]\n",
        "    k2=0\n",
        "\n",
        "    for i in t:\n",
        "        val=0\n",
        "        count=0\n",
        "        flag=0\n",
        "        k=0\n",
        "        for j in x_axis:\n",
        "            if(i==j):\n",
        "                val=val+y_axis[k]\n",
        "                count=count+1\n",
        "                flag=1\n",
        "            k=k+1\n",
        "        if(flag==1):\n",
        "            vals[k2] = val/count\n",
        "        if(flag==0 and k2!=0):\n",
        "            vals[k2] = vals[k2-1]\n",
        "        k2+=1\n",
        "\n",
        "    plt.plot(t, vals)\n",
        "\n",
        "#     if(yes):\n",
        "#         first_line = LineString(np.column_stack((t, vals)))\n",
        "#         return first_line\n",
        "#     else:\n",
        "#         second_line = LineString(np.column_stack((t, vals)))\n",
        "#         return second_line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqvqVG2tZ5ef"
      },
      "outputs": [],
      "source": [
        "l1 = preds(model1, X_test1, size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L9SkZYEZ5ef"
      },
      "outputs": [],
      "source": [
        "# l = preds(model, X_test2, size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4neWAjpZ5ef"
      },
      "outputs": [],
      "source": [
        "l3 = preds(model3, X_test3, size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnCR4R83Z5eg"
      },
      "outputs": [],
      "source": [
        "# l4 = preds(model3, X_test4, size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_krNFGidZ5eg"
      },
      "outputs": [],
      "source": [
        "def plot_all(model, l, X_test2, y_test2, Y_test2, size = 100):\n",
        "\n",
        "#     l = preds(model, X_test2, size)\n",
        "    sorted_c, sorted_d = sortIt(l, Y_test2)\n",
        "    plotIt(sorted_c, y_test2)\n",
        "    plotIt(sorted_d, y_test2)\n",
        "    return sorted_c[:,0], sorted_c[:,1], sorted_d[:,0], sorted_d[:,1], val1, val2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "-nU82v-KZ5eg",
        "outputId": "0eb79da6-800f-44b3-98f6-d3c2adbad410"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Output Layer')"
            ]
          },
          "execution_count": 270,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from shapely.geometry import LineString\n",
        "\n",
        "scx1, scy1, sdx1, sdy1 = plot_all(model1, l1, X_test1, y_test1, Y_test1)\n",
        "plt.scatter(scx1, scy1)\n",
        "plt.scatter(sdx1, sdy1)\n",
        "plt.plot(np.linspace(2.27,2.27,scy3.shape[0]),scy3)\n",
        "# scx2, scy2, sdx2, sdy2 = plot_all(model3, l, X_test2, y_test2, Y_test2)\n",
        "# scx3, scy3, sdx3, sdy3 = plot_all(model3, l3, X_test3, y_test3, Y_test3)\n",
        "plt.xlabel('T/J')\n",
        "plt.ylabel('Output Layer')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBDBS_aJZ5eg",
        "outputId": "e3eeed86-e6d2-4ea1-d6be-de648c29d4c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Output Layer')"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "scx2, scy2, sdx2, sdy2 = plot_all(model3, l, X_test2, y_test2, Y_test2)\n",
        "plt.scatter(scx2, scy2)\n",
        "plt.scatter(sdx2, sdy2)\n",
        "plt.plot(np.linspace(2.27,2.27,scy3.shape[0]),scy3)\n",
        "plt.xlabel('T/J')\n",
        "plt.ylabel('Output Layer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u35lZI77Z5eg",
        "outputId": "9af944ae-5aad-4d1e-bca4-084bbd2e1aa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Output Layer')"
            ]
          },
          "execution_count": 261,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcPElEQVR4nO3df5Ac9Xnn8feHRTJr80MBiV+SMApRUBQQBjZIDjgoxgQJgyE+H4UCIRBjigTOvqKgjA4MxkARWxyOMcQyNhwQCIRydLLAAkVnG1yxg8IKjGQZMDIO0kr8ECYIDDKSluf+6FlpNDsz2z2antmd/ryqtrT9zLdnnm839LPd/Z1vKyIwM7Pi2qXdCZiZWXu5EJiZFZwLgZlZwbkQmJkVnAuBmVnB7druBLIaO3ZsHHzwwe1Ow8xsRFm+fPlrETGu2msjrhAcfPDB9Pb2tjsNM7MRRdKLtV7zpSEzs4JzITAzKzgXAjOzgnMhMDMrOBcCM7OCy23UkKQ7gFOAVyPisCqvC/gacDLwDnBuRDyZRy4n3vQoz7/69rblyft+gKWXzKy7zrSrH+HNd/u3Le/5vi5WXDOrZvsrF67kvmVr6Y+gS2LO9Ilcd/rhNdtPuWIxv+3fPuHfbl3i2etPblofsuYz/fqlvPLW5m3L++0xmmVXnFizPWTfRmd969/58S9f37Z87CF7c+9nPty098+6jRrp88Kn1jFvyXOsf2MTB47p5rKTDuX0I8fXXuGhS2D5nRD9oC44+lw45aba7Vc8AN//Emzsg70mwAlXwbQzare/ZTq89uz25bFT4OJlzWufNf9G1sna/tr9oX/T9uWubvjCy7XbZ92mWTWyjbLmdOMU+M1L25d3PwAufbZ2+4zyPCO4E6j9fy3MBiaXfi4AvpFHEpUHB4DnX32bE296tOY6lQcggDff7Wfa1Y9UbX/lwpXc8/ga+kszufZHcM/ja7hy4cqq7SuLAMBv+4MpVyxuSh+y5lN5QAR45a3NTL9+adX2kH0bVRYBgB//8nXO+ta/N+X9s26jRvq88Kl1XPadp1n3xiYCWPfGJi77ztMsfGpd9RUeugR6b08OEJD823t7Eq9mxQPw4Gdh41ogkn8f/GwSr6byoA7J8i3Tm9M+a/6NrJO1fWURgGT52v2rt8+6TbNqZBtlzamyCECyfOOUpnQBciwEEfEj4PU6TU4D7o7E48AYSQc0O4/Kg8NQcWDQAWio+H3L1maKVxaBoeJZ+5A1n8oD4lBxyL6NKovAUPGs7591GzXS52seXMWWin20pT+45sFVO8R0jdA1Sv5KrKZW/Ptfgi0VB7ktm5J4NZUH9WbHs+bfyDpZ45VFYKh41m2aVSPbKGtOlUVgqHgD2nmPYDxQfmTqK8UGkXSBpF5JvRs2bGhJcln013imQ6143oZbPp3iv97ZkikeUb1o1YqzsS9bPG+18qwVb2SdRj4ji7y3aSP5D7f9THsLgarEqh6pIuK2iOiJiJ5x46p+Q7qtulStK7XjeRtu+RRVf43/vWrF2WtCtnje1JUt3sg6jXxGFnlv00byH277mfYWgj5gYtnyBGB9sz9k8r4fyBSH5KZklvic6RMzxXfrqn5ArhXP2oes+ey3x+hMcci+jY49ZO9M8azv38h+zts/bf0olSdhEUm8qhOuglHdO8ZGdSfxasbWuEbcrPjR52aLN7JOI5+RRdZtmlUj+WfNafcaV8xrxRvQzkKwCDhHiRnAxoho3kWvkqWXzBx0MBhqNMmKa2YNOuDUG7Fy3emHc/aMg7b9xd0lcfaMg2qO0nn2+pMHHfTrjRrK2oes+Sy74sRBB/2hRtBk3Ub3fubDgw769UYNZX3/rNvod94/KlO8kXW+uftF3N3/MbbGLkTA1tiFu/s/xjd3v6j6B0w7A069GfaaCCj599Sba48muXjZ4IN4vVFAWdufchP0fHr7X7fqSpbrjYjJuk7W9p/8VrZ41m2aVSPbKGtOlz47+KDf5FFDyuuZxZLuA2YCY4FXgKuBUQARMb80fPQWkpFF7wDnRcSQs8n19PSEJ52znTUwAqj85u+oLjHvU0fUHA6adh1dkxTg//uJPuYuWMmmLduvF3eP6uKGTx5ef8ip1Zf3cNAOJWl5RPRUey237xFExJwhXg+gxp9GZvkaOBBn+U5A1nUa+QxLYdoZ2Q78LhxDGnHTUJs1y+lHjs/9oNyKz7A6BsbsDwzXHBizDy4GZTzFhFlKC59ax9wFK3f4QtncBStrf6HM2i/v7xF0CBcCs5TmLXluh+v9AJu29DNvyXNtysiG1MiY/RUPwFcPgy+OSf5t1reQhzEXArOU1r9R/durteI2DGQds5/3lBTDlAuBWUoHjulOFT/+g8dz/AePb0VKNpSsY/YLeinJhcAspctOOpTuUTt+t6F7VBeXnXRomzKyIWUdsz8Mp39oBY8aMkvJw0FHqCzDTfeaULosVCXewVwIzDLwcNAOd8JVOw43heZOSTFM+dKQmdmAvKekGKZ8RmBmVi7rN5c7gM8IzMwKzoXAzKzgfGnILEeZH3Zv1gYuBGY5GZibaGBaioG5iQAXAxtWXAjMmuyxFx8DYMvLtecmciGw4cT3CMxysq7GHES14mbt4kJglpOBR4WmjZu1iwuBWU76azwGtlbcrF1cCMxyMr7GbKW14mbt4kJglhPPVmojhUcNmeXEs5XaSOFCYJYjz1ZqI4EvDZmZFZwLgZlZwbkQmJkVnAuBmVnBuRCYmRWcC4GZWcG5EJiZFZwLgZlZwbkQmJkVXK6FQNIsSc9JWi3p8iqv7yXpQUlPS1ol6bw88zEzs8FyKwSSuoBbgdnAVGCOpKkVzS4Cfh4RRwAzgf8taXReOZmZ2WB5nhEcA6yOiBciYjNwP3BaRZsA9pAkYHfgdWBrjjmZmVmFPAvBeGBt2XJfKVbuFuAPgPXASuBzEfFe5RtJukBSr6TeDRs25JWvmVkh5VkIqj2Pr/LRTCcBPwUOBD4E3CJpz0ErRdwWET0R0TNu3Lhm52lmVmh5FoI+YGLZ8gSSv/zLnQcsiMRq4FfAlBxzMjOzCnkWgieAyZImlW4AnwksqmizBjgBQNJ+wKHACznmZGZmFXJ7ME1EbJV0MbAE6ALuiIhVki4svT4fuBa4U9JKkktJn4+I1/LKyczMBsv1CWURsRhYXBGbX/b7euDP8szBzMzq8zeLzcwKzoXAzKzgXAjMzArOhcDMrOBcCMzMCs6FwMys4FwIzMwKzoXAzKzgXAjMzArOhcDMrOBcCMzMCs6FwMys4FwIzMwKzoXAzKzgXAjMzArOhcDMrOBcCMzMCs6FwMys4FwIzMwKzoXAzKzgXAjMzArOhcDMrODqFgJJu0g6o1XJmJlZ69UtBBHxHnBxi3IxM7M2SHNpaKmkSyVNlLT3wE/umZmZWUvsmqLNX5f+vagsFsDvNj8dMzNrtSELQURMakUiZmbWHkNeGpL0fklXSrqttDxZ0in5p2ZmZq2Q5h7B/wE2A39cWu4DrsstIzMza6k0heCQiPgKsAUgIjYByjUrMzNrmTSFYLOkbpIbxEg6BHg3zZtLmiXpOUmrJV1eo81MST+VtErSY6kzNzOzpkgzauiLwCPAREn3AscC5w61kqQu4FbgRJLLSU9IWhQRPy9rMwb4B2BWRKyRtG/WDpiZ2c5JM2roXyUtB2aQXBL6XES8luK9jwFWR8QLAJLuB04Dfl7W5i+ABRGxpvRZr2bM38zMdlKaUUPfAaYDD0fEQymLAMB4YG3Zcl8pVu73gd+R9Kik5ZLOqZHDBZJ6JfVu2LAh5cebmVkaae4RzAfOAp6X9HeSpqR872o3lKNieVfgaODjwEnAFyT9/qCVIm6LiJ6I6Bk3blzKjzczszSGLAQR8f8i4izgKOA/Saac+Imk8ySNqrNqHzCxbHkCsL5Km0ci4u3SmcaPgCOydMDMzHZOqmmoJe1DcoP4fOAp4GskhWFpndWeACZLmiRpNHAmsKiizXeBj0jaVdL7SS5BPZOpB2ZmtlOGvFksaQEwBfhH4NSIeKn00j9L6q21XkRslXQxsAToAu6IiFWSLiy9Pj8inpH0CLACeA/4dkT8bOe6ZGZmWaQZPnpLRPyg2gsR0VNvxYhYDCyuiM2vWJ4HzEuRh5mZ5SDN8NEfSDoMmArsVha/O8/EzMysNdJcGroamElSCBYDs4F/A1wIzMw6QJqbxZ8CTgBejojzSEb1vC/XrMzMrGXSFIJNpUdWbpW0J/AqfiiNmVnHSHOzuLc0J9C3gOXAb4D/yDMpMzNrnTQ3i/+29Ov80lDPPYG000yYmdkwl+aMYJuI+E8ASWuAg/JIyMzMWivVN4ur8INpzMw6RKOFoHLyODMzG6FqXhqS9HWqH/AFjMkrITMza6169whqziM0xGtmZjaC1CwEEXFXKxMxM7P2aPQegZmZdQgXAjOzgkvzzOJj08TMzGxkSnNG8PWUMTMzG4HqDR/9MPDHwDhJl5S9tCfJE8fMzKwD1Bs+OhrYvdRmj7L4myRTU5uZWQeoN3z0MeAxSXdGxIstzMnMzFoozaRzd0oa9A3jiPhoDvmYmVmLpSkEl5b9vhvw34Ct+aRjZmatluZ5BMsrQj+W9FhO+ZiZWYuleXj93mWLuwBHA/vnlpGZmbVUmktDy0lmIRXJJaFfAZ/OMykzM2udNJeGJrUiETMza480l4Z2A/4WOI7kzODfgG9ExG9zzs3MzFogzaWhu4G32D6txBzgH4H/nldSZmbWOmkKwaERcUTZ8g8lPZ1XQmZm1lppJp17StKMgQVJ04Ef55eSmZm1UpozgunAOZLWlJYPAp6RtBKIiJiWW3ZmZpa7NIVgVu5ZmJlZ26S5NHRdRLxY/lMeq7eipFmSnpO0WtLlddr9kaR+SZ7V1MysxdIUgj8sX5C0K8m3i+uS1AXcCswGpgJzJE2t0e7LwJI0CZuZWXPVLASS5kp6C5gm6U1Jb5WWXwG+m+K9jwFWR8QLEbEZuB84rUq7/wH8C/Bq9vTNzGxn1SwEEXFDROwBzIuIPSNij9LPPhExN8V7jwfWli33lWLbSBoP/Dkwv94bSbpAUq+k3g0bNqT4aDMzSyvNzeKHJf1JZTAifjTEeqoSq3yuwd8Dn4+Ifqla822fdRtwG0BPT8+gZyOYmVnj0hSCy8p+343kks9yYKgH0/QBE8uWJwDrK9r0APeXisBY4GRJWyNiYYq8zMysCdJMOndq+bKkicBXUrz3E8BkSZOAdcCZwF9UvPe2Ce0k3Qk85CJgZtZaac4IKvUBhw3VKCK2SrqYZDRQF3BHRKySdGHp9br3BczMrDXSzD76dbZf298F+BCQaq6hiFgMLK6IVS0AEXFumvc0M7PmSnNG0Fv2+1bgvojwXENmZh0iTSH4Z+D3SM4KfunnEJiZdZZ6XyjbVdJXSO4J3AXcA6yV9BVJo1qVoJmZ5aveFBPzgL2BSRFxdEQcCRwCjAFubEFuZmbWAvUKwSnAZyLirYFARLwJ/A1wct6JmZlZa9QrBBERg77FGxH9DP6GsJmZjVD1CsHPJZ1TGZR0NvBsfimZmVkr1Rs1dBGwQNJfk0wpEcAfAd0kE8WZmVkHqFkIImIdMF3SR0meSSDg4Yj4fquSMzOz/KWZa+gHwA9akIuZmbVBmieUmZlZB3MhMDMrOBcCM7OCcyEwMys4FwIzs4JzITAzKzgXAjOzgnMhMDMrOBcCM7OCcyEwMys4FwIzs4JzITAzKzgXAjOzgnMhMDMrOBcCM7OCcyEwMys4FwIzs4JzITAzKzgXAjOzgnMhMDMruFwLgaRZkp6TtFrS5VVeP0vSitLPTyQdkWc+ZmY2WG6FQFIXcCswG5gKzJE0taLZr4DjI2IacC1wW175mJlZdXmeERwDrI6IFyJiM3A/cFp5g4j4SUT8V2nxcWBCjvmYmVkVeRaC8cDasuW+UqyWTwMPV3tB0gWSeiX1btiwoYkpmplZnoVAVWJRtaH0pySF4PPVXo+I2yKiJyJ6xo0b18QUzcxs1xzfuw+YWLY8AVhf2UjSNODbwOyI+HWO+ZiZWRV5nhE8AUyWNEnSaOBMYFF5A0kHAQuAv4yIX+SYi5mZ1ZDbGUFEbJV0MbAE6ALuiIhVki4svT4fuArYB/gHSQBbI6Inr5zMzGywPC8NERGLgcUVsfllv58PnJ9nDmZmVp+/WWxmVnAuBGZmBedCYGZWcC4EZmYF50JgZlZwLgRmZgXnQmBmVnAuBGZmBedCYGZWcC4EZmYF50JglqcVD8BXD4Mvjkn+XfFAuzMyGyTXuYbMCm3FA/DgZ2HLpmR549pkGWDaGe3Ly6yCzwjM8vL9L20vAgO2bEriZsOIC4FZXjb2ZYubtYkLgVle9pqQLW7WJi4EZnmZ/GfZ4mZt4kJglpfn/zVb3KxNXAjM8uJ7BDZCePioWV72mpAMGa0Wt2Fr4VPrmLfkOda/sYkDx3Rz2UmHcvqR49udVq58RmCWlxOuglHdO8ZGdSdxG5YWPrWOuQtWsu6NTQSw7o1NzF2wkoVPrWt3arlyITDLy7Qz4NSbYa+JgJJ/T73ZXyYbxuYteY5NW/p3iG3a0s+8Jc+1KaPW8KUhsyxWPJB8IWxjX3KJ54Sr6h/Yp53hA/8Isv6NTZnincJnBGZpDUwZsXEtENunjPD8QR3jwDHdmeKdwoXALC1PGdHxLjvpULpHde0Q6x7VxWUnHdqmjFrDl4bM0vJw0BEpyyiggXjRRg25EJil5eGgI87AKKCBG8ADo4CAusWg0w/8lXxpyCwtDwcdcYo6CigrFwKztDwcdMQp6iigrHxpyCwLDwcdUQ4c0826Kgf9Th8FlJXPCKy4GnmMZNZ1/KjKtirqKKCsfEZgxbTiAfjuRdC/OVneuDZZhtp/8Wddx4+qbLuijgLKKtdCIGkW8DWgC/h2RPxdxesqvX4y8A5wbkQ82fREbpkOrz27fXnsFLh4Wf11bjgI3t24ffl9e8HcNbXbP3QJLL8Toh/UBUefC6fcVLv9tftDf9kpa1c3fOHl5vUhaz43ToHfvLR9efcD4NJna7eH7Nvork/Arx7bvjzpePirRc17/yzb6OHPbz+gD+jfnMRrHaSzrlPvewc1PiPrhGcn3vQoz7/69rblyft+gKWXzGxa+ysXruS+ZWvpj6BLYs70iVx3+uE12zeyTtb2vzf3e2yN7cu7Clbf8PG6OeWpkW2UdT9Pv34pr7y1/b+9/fYYzbIrTmxaH3K7NCSpC7gVmA1MBeZImlrRbDYwufRzAfCNpidSeXCAZPmW6bXXqTwAQbJ8w0HV2z90CfTenhx0Ifm39/YkXk1lEYBk+dr9m9OHrPlUFgFIlm+cUr09ZN9GlUUAkuW7PtGc98+6jTa9ni3ewDpR4/sFteJZJzyrPKgDPP/q25x406NNaX/lwpXc8/ga+iM56vZHcM/ja7hy4cqq7RtZJ2v7yiIAsDWSeDV5TyLXyDbKmlNlEQB45a3NTL9+aVP6APneIzgGWB0RL0TEZuB+4LSKNqcBd0ficWCMpAOamkXlwWGoOAw+AA0VX35ntnhlERgqnrUPWfOpLAJDxSH7NqosAkPFs75/I/s5Z+tjn0zxrEMdKw/qzY7ft6zKdybqxBtZJ2u8sggMFc97+Ggj2yhrTpVFYKh4I/IsBOOB8q3RV4plbYOkCyT1SurdsGFD0xPdadGfLZ634ZZPQX15yxm8E6N3iL0To/nyluqXhYbbUMeBv3LTxhtZp5HPyCLvbdpI/sNtP0O+hUBVYpVbJ00bIuK2iOiJiJ5x48Y1JbmmUle2eN6GWz6donvvVPG4Ooirg+/FR7h8y/n0vTeW90L0vTeWy7ecz/fiI1XfZrhNeNalav971o43sk4jn5FF3tu0kfyH236GfAtBHzCxbHkCsL6BNjtnbI3r3LXikNyUzBI/+txs8a4aO7xWPGsfsuaze42rcbXikH0bTTo+Wzzr+2fdRo30efaXoWvHv/DpGp3Eq5gzfSKL3juO4zbfzO++ey/Hbb6ZRe8dx5zpE6u2zzrUcfK+H8g1XivPWvFG1ska37XG8bVWPO/ho41so6w57bfH6EzxRuRZCJ4AJkuaJGk0cCZQOURkEXCOEjOAjRFR58J0Ay5eNvhgMNSIm7lrBh9w6o1YOeUm6Pn09r+41ZUs1xql84WXBx/0640aytqHrPlc+uzgA+BQo4aybqO/WjT4oF9v1FDW98+6jRrp87Qz4LRbd/xm8Wm31hwBdN3ph3P2jIO2/XXYJXH2jINqjig5/cjx3PDJwxk/phsB48d0c8MnD685mmTpJTMHHcTrjQLK2j5r/o2sk7X96hs+PuigX2/UUNZtmlUj2yhrTsuuOHHQQb/Zo4YUTboWV/XNpZOBvycZPnpHRFwv6UKAiJhfGj56CzCLZPjoeRHRW+89e3p6ore3bhMzM6sgaXlE9FR7LdfvEUTEYmBxRWx+2e8BXJRnDmZmVp+nmDAzKzgXAjOzgnMhMDMrOBcCM7OCy3XUUB4kbQBebHD1scBrTUxnJHCfi8F9Load6fMHI6LqN3JHXCHYGZJ6aw2f6lTuczG4z8WQV599acjMrOBcCMzMCq5oheC2difQBu5zMbjPxZBLnwt1j8DMzAYr2hmBmZlVcCEwMyu4jiwEku6Q9Kqkn9V4XZJulrRa0gpJR7U6x2ZK0d+ZkjZK+mnp56pW59hskiZK+qGkZyStkvS5Km06bT+n6XNH7WtJu0n6D0lPl/p8TZU2nbaf0/S5ufs5IjruB/gT4CjgZzVePxl4mOQJaTOAZe3OOef+zgQeaneeTe7zAcBRpd/3AH4BTO3w/Zymzx21r0v7bvfS76OAZcCMDt/Pafrc1P3ckWcEEfEj4PU6TU4D7o7E48AYSXUeTTW8pehvx4mIlyLiydLvbwHPMPh51522n9P0uaOU9t1vSoujSj+VI1w6bT+n6XNTdWQhSGE8sLZsuY8O/x8K+HDpVPNhSX/Y7mSaSdLBwJEkfzmV69j9XKfP0GH7WlKXpJ8CrwJLI6Lj93OKPkMT93NRC0G1J5x28jjaJ0nmGTkC+DqwsL3pNI+k3YF/Af5nRLxZ+XKVVUb8fh6izx23ryOiPyI+RPJM82MkHVbRpOP2c4o+N3U/F7UQ9AHlT5eeAKxvUy65i4g3B041I3lq3ChJY9uc1k6TNIrkgHhvRCyo0qTj9vNQfe7UfQ0QEW8Aj5I82rZcx+3nAbX63Oz9XNRCsAg4pzTaYAawMSJeandSeZG0f+n50Eg6hmS//7q9We2cUn9uB56JiJtqNOuo/Zymz522ryWNkzSm9Hs38DHg2Ypmnbafh+xzs/dzrs8sbhdJ95HcVR8rqQ+4muSGC5E8M3kxyUiD1cA7wHntybQ5UvT3U8DfSNoKbALOjNLQgxHsWOAvgZWla6kA/ws4CDpzP5Ouz522rw8A7pLURXKweyAiHpJ0IXTsfk7T56buZ08xYWZWcEW9NGRmZiUuBGZmBedCYGZWcC4EZmYF50JgZlZwLgRmGUnap2zWx5clrStbHi3pm5KOlXSnpE+1O1+zobgQmGUUEb+OiA+VpgCYD3x1YDkiNgPTgcfbmqRZBi4EZk0k6Q+AX0REf7tzMUvLhcCsuWYDj7Q7CbMsXAjMmuskXAhshHEhMGsSSe8HxkRER8x8acXhQmDWPH8K/LDdSZhl5UJg1jyV9wd2Bd5tUy5mqXn2UbMmkfQkMD0itkjaBXgCOCciVrU5NbO6fEZg1iQRcVSpCBwI/Ax43EXARgKfEZiZFZzPCMzMCs6FwMys4FwIzMwKzoXAzKzgXAjMzAru/wONP0mfOISJXQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(scx3, scy3)\n",
        "plt.scatter(sdx3, sdy3)\n",
        "# plt.scatter(sdx3, sdy3)\n",
        "plt.plot(np.linspace(2.27,2.27,scy3.shape[0]),scy3, color='g')\n",
        "plt.xlabel('T/J')\n",
        "plt.ylabel('Output Layer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlV7QaWKZ5eg"
      },
      "outputs": [],
      "source": [
        "def plotIt2(sorted, y_test, latt):\n",
        "\n",
        "    t = np.arange(1, 3.51, 0.1)\n",
        "    vals = np.zeros(t.shape[0])\n",
        "    x_axisc = sorted[:,0]\n",
        "    y_axis = sorted[:,1]\n",
        "    k2=0\n",
        "\n",
        "    for i in t:\n",
        "        val=0\n",
        "        count=0\n",
        "        flag=0\n",
        "        k=0\n",
        "        for j in x_axis:\n",
        "            if(i==j):\n",
        "                val=val+y_axis[k]\n",
        "                count=count+1\n",
        "                flag=1\n",
        "            k=k+1\n",
        "        if(flag==1):\n",
        "            vals[k2] = val/count\n",
        "        if(flag==0 and k2!=0):\n",
        "            vals[k2] = vals[k2-1]\n",
        "        k2+=1\n",
        "\n",
        "    plt.plot(t, (vals-2.27)*(latt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aV4w6YAZ5eh"
      },
      "outputs": [],
      "source": [
        "# plt.scatter(scx1, (scy1-2.27)*(10))\n",
        "# plt.scatter(sdx1, (sdy1-2.27)*(10))\n",
        "# sorted_c, sorted_d = sortIt(l, Y_test1)\n",
        "# plotIt2(sorted_c, y_test1, 10)\n",
        "# plotIt2(sorted_d, y_test1, 10)\n",
        "# plt.xlabel('$tL^{1/v}$')\n",
        "# plt.ylabel('Output Layer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1kBTfArZ5eh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYkujZv-1YfP"
      },
      "source": [
        "##### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnSEJIB0KFKT",
        "outputId": "9b38133d-8bc5-4240-cb0b-ca0054c9f968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 16s 369ms/step - loss: 0.5765 - binary_accuracy: 0.9080 - val_loss: 0.0919 - val_binary_accuracy: 0.9700\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 11s 341ms/step - loss: 0.0624 - binary_accuracy: 0.9820 - val_loss: 0.0451 - val_binary_accuracy: 0.9800\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 11s 345ms/step - loss: 0.0301 - binary_accuracy: 0.9930 - val_loss: 0.0032 - val_binary_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 11s 338ms/step - loss: 0.0195 - binary_accuracy: 0.9950 - val_loss: 0.0496 - val_binary_accuracy: 0.9900\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 11s 342ms/step - loss: 0.0116 - binary_accuracy: 0.9960 - val_loss: 0.0022 - val_binary_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 9s 289ms/step - loss: 0.0056 - binary_accuracy: 0.9980 - val_loss: 0.0131 - val_binary_accuracy: 0.9900\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 9s 288ms/step - loss: 0.0029 - binary_accuracy: 0.9990 - val_loss: 0.0180 - val_binary_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 9s 281ms/step - loss: 0.0051 - binary_accuracy: 0.9990 - val_loss: 0.0049 - val_binary_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 10s 299ms/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.0152 - val_binary_accuracy: 0.9900\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 9s 276ms/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 0.0158 - val_binary_accuracy: 0.9900\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "          layers.Reshape(target_shape=(40,40,1), input_shape=(40,40)),\n",
        "          layers.Conv2D(128, (3,3), padding='valid', activation='relu'),\n",
        "          layers.Flatten(),\n",
        "          layers.Dense(128, activation='relu'),\n",
        "          layers.Dropout(.5),\n",
        "          layers.Dense(2, activation='softmax')\n",
        "        ])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "hist = model.fit(X_train4[:1000], y_train4[:1000], epochs=10, batch_size=32, validation_data = (X_test4[:100], y_test4[:100]))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}